{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "from random import randint\n",
    "import random\n",
    "import math\n",
    "from collections import defaultdict\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import svm\n",
    "import operator\n",
    "import sklearn.metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "from sklearn.naive_bayes import GaussianNB as GNB\n",
    "from pandas import DataFrame, read_csv\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from deap import creator, base, tools, algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         Description  Category\n",
      "0  Was walking along crowded street, holding mums...         0\n",
      "1  This incident took place in the evening.I was ...         0\n",
      "2  I WAS WAITING FOR THE BUS. A MAN CAME ON A BIK...         1\n",
      "3                 Incident happened inside the train         0\n",
      "4  I witnessed an incident when a chain was bruta...         0\n"
     ]
    }
   ],
   "source": [
    "file1 = '../../../data/safecity/binary/commenting/train.csv'\n",
    "df = pd.read_csv(file1)\n",
    "print(df.head())\n",
    "\n",
    "corpus = list(df[\"Description\"])\n",
    "target = list(df[\"Category\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# infinity = float(\"inf\") #sentinel maximum value\n",
    "# m = 70 #no of bats (50-70)\n",
    "# T = 100 # no of iterations(100)\n",
    "\n",
    "# bat_pos = defaultdict(list)\n",
    "# bat_vel = defaultdict(list)\n",
    "# bat_loudness = []\n",
    "# bat_rate = []\n",
    "# bat_fitness = []\n",
    "# bat_frequency = []\n",
    "\n",
    "# global_bat_pos = []\n",
    "# init_rate_vector = []\n",
    "# feature_vector = []\n",
    "\n",
    "# #hyperparameters\n",
    "# alpha = 0.9\n",
    "# gamma = 0.9\n",
    "# epsilon = random.uniform(-1,1)\n",
    "# fmin=0\n",
    "# fmax =1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7201, 8504)\n",
      "['00', '000', '00am', '00pm', '01', '03', '0300', '05', '06', '0740', '0800am', '0830', '08826862360', '0900', '0930', '0f', '10', '100', '1000', '1000am', '1011am', '1012', '1015', '1030', '1030am', '1030ish', '1030pm', '1050', '10pm', '10th', '11', '1115', '1130', '1139', '1150', '11am', '11h', '11th', '12', '1213', '1214', '1230', '1245', '12th', '12yearold', '12years', '12yrs', '13', '1314', '13th']\n",
      "8504\n",
      "                                         Description  Category\n",
      "0  Buses approaching to this place is highly unsafe.         1\n",
      "1                        a man was commenting at me.         1\n",
      "2                                    in a share auto         0\n",
      "3  I was coming out of a club at night with a few...         1\n",
      "4  One of my friends was molested in the crowd. T...         0\n",
      "(990, 8504)\n",
      "['00', '000', '00am', '00pm', '01', '03', '0300', '05', '06', '0740', '0800am', '0830', '08826862360', '0900', '0930', '0f', '10', '100', '1000', '1000am', '1011am', '1012', '1015', '1030', '1030am', '1030ish', '1030pm', '1050', '10pm', '10th', '11', '1115', '1130', '1139', '1150', '11am', '11h', '11th', '12', '1213', '1214', '1230', '1245', '12th', '12yearold', '12years', '12yrs', '13', '1314', '13th']\n",
      "8504\n",
      "                                         Description  Category\n",
      "0  During morning, a woman was walking by and thi...         1\n",
      "1  A man tried to brush his penis off of a woman'...         0\n",
      "2  This happened to a fellow passenger of mine tr...         0\n",
      "3                                             ogling         0\n",
      "4  When I was returning my home after finishing m...         0\n",
      "(1701, 8504)\n",
      "['00', '000', '00am', '00pm', '01', '03', '0300', '05', '06', '0740', '0800am', '0830', '08826862360', '0900', '0930', '0f', '10', '100', '1000', '1000am', '1011am', '1012', '1015', '1030', '1030am', '1030ish', '1030pm', '1050', '10pm', '10th', '11', '1115', '1130', '1139', '1150', '11am', '11h', '11th', '12', '1213', '1214', '1230', '1245', '12th', '12yearold', '12years', '12yrs', '13', '1314', '13th']\n",
      "8504\n"
     ]
    }
   ],
   "source": [
    "#do once\n",
    "# nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 1), stop_words=stop_words)\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "print(X.shape)\n",
    "print(vectorizer.get_feature_names()[0:50])\n",
    "print(len(vectorizer.get_feature_names()))\n",
    "\n",
    "X_train = X\n",
    "Y_train = target\n",
    "\n",
    "file2 = '../../../data/safecity/binary/commenting/dev.csv'\n",
    "df_dev = pd.read_csv(file2)\n",
    "print(df_dev.head())\n",
    "corpus_dev = list(df_dev[\"Description\"])\n",
    "target_dev = list(df_dev[\"Category\"])\n",
    "X_dev = vectorizer.transform(corpus_dev)\n",
    "print(X_dev.shape)\n",
    "print(vectorizer.get_feature_names()[0:50])\n",
    "print(len(vectorizer.get_feature_names()))\n",
    "Y_dev = target_dev\n",
    "\n",
    "file3 = '../../../data/safecity/binary/commenting/test.csv'\n",
    "df_test = pd.read_csv(file3)\n",
    "print(df_test.head())\n",
    "corpus_test = list(df_test[\"Description\"])\n",
    "target_test = list(df_test[\"Category\"])\n",
    "X_test = vectorizer.transform(corpus_test)\n",
    "print(X_test.shape)\n",
    "print(vectorizer.get_feature_names()[0:50])\n",
    "print(len(vectorizer.get_feature_names()))\n",
    "Y_test = target_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7201, 8504) (990, 8504)\n"
     ]
    }
   ],
   "source": [
    "z1, z2 = X_train, X_dev\n",
    "print(z1.shape, z2.shape)\n",
    "n = z1.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#auxillary  functions\n",
    "def extract_subset(z,cols):\n",
    "    return z[:,cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_calc_fitness(x, mode=None): # SVM classifier\n",
    "    if mode in (None, 'dev'): X_eval, Y_eval = X_dev, Y_dev\n",
    "    elif mode == 'test': X_eval, Y_eval = X_test, Y_test\n",
    "    elif mode == 'train': X_eval,  Y_eval = X_train, Y_train\n",
    "        \n",
    "    for i in range(0,len(x)):\n",
    "        x[i] = x[i] > 0.5\n",
    "    cols = []\n",
    "    for j in range(0, n):\n",
    "        if x[j] == 1:\n",
    "            cols.append(j)\n",
    "    z1_prime = extract_subset(X_train, cols)\n",
    "    z2_prime = extract_subset(X_eval, cols)\n",
    "    clf = svm.LinearSVC(C=1.0)\n",
    "    clf.fit(z1_prime, Y_train)\n",
    "    y_pred = clf.predict(z2_prime)\n",
    "    \n",
    "    acc = sklearn.metrics.accuracy_score(Y_eval,y_pred)\n",
    "    pre = sklearn.metrics.precision_score(Y_eval,y_pred)\n",
    "    fscore = sklearn.metrics.f1_score(Y_eval,y_pred)\n",
    "    recall = sklearn.metrics.recall_score(Y_eval,y_pred)\n",
    "    return acc,pre,fscore,recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf_calc_fitness(x, mode=None): # RF classifier\n",
    "    if mode in (None, 'dev'): X_eval, Y_eval = X_dev, Y_dev\n",
    "    elif mode == 'test': X_eval, Y_eval = X_test, Y_test\n",
    "    elif mode == 'train': X_eval,  Y_eval = X_train, Y_train\n",
    "        \n",
    "    for i in range(0,len(x)):\n",
    "        x[i] = x[i] > 0.5\n",
    "    cols = []\n",
    "    for j in range(0, n):\n",
    "        if x[j] == 1:\n",
    "            cols.append(j)\n",
    "    z1_prime = extract_subset(X_train, cols)\n",
    "    z2_prime = extract_subset(X_eval, cols)\n",
    "    clf = RandomForestClassifier(n_estimators=100, n_jobs=10, random_state=0)\n",
    "    clf.fit(z1_prime, Y_train)\n",
    "    y_pred = clf.predict(z2_prime)\n",
    "    \n",
    "    acc = sklearn.metrics.accuracy_score(Y_eval,y_pred)\n",
    "    pre = sklearn.metrics.precision_score(Y_eval,y_pred)\n",
    "    fscore = sklearn.metrics.f1_score(Y_eval,y_pred)\n",
    "    recall = sklearn.metrics.recall_score(Y_eval,y_pred)\n",
    "    return acc,pre,fscore,recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_calc_fitness(x, mode=None): # KNN classifier\n",
    "    if mode in (None, 'dev'): X_eval, Y_eval = X_dev, Y_dev\n",
    "    elif mode == 'test': X_eval, Y_eval = X_test, Y_test\n",
    "    elif mode == 'train': X_eval,  Y_eval = X_train, Y_train\n",
    "\n",
    "    for i in range(0,len(x)):\n",
    "        x[i] = x[i] > 0.5\n",
    "    cols = []\n",
    "    for j in range(0, n):\n",
    "        if x[j] == 1:\n",
    "            cols.append(j)\n",
    "    z1_prime = extract_subset(X_train, cols)\n",
    "    z2_prime = extract_subset(X_eval, cols)\n",
    "    clf = KNN(3,weights='uniform')\n",
    "    clf.fit(z1_prime, Y_train)\n",
    "    y_pred = clf.predict(z2_prime)\n",
    "    \n",
    "    acc = sklearn.metrics.accuracy_score(Y_eval,y_pred)\n",
    "    pre = sklearn.metrics.precision_score(Y_eval,y_pred)\n",
    "    fscore = sklearn.metrics.f1_score(Y_eval,y_pred)\n",
    "    recall = sklearn.metrics.recall_score(Y_eval,y_pred)\n",
    "    return acc,pre,fscore,recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nb_calc_fitness(x, mode=None): # Gaussian NB (Naive Bayes) classifier\n",
    "    if mode in (None, 'dev'): X_eval, Y_eval = X_dev, Y_dev\n",
    "    elif mode == 'test': X_eval, Y_eval = X_test, Y_test\n",
    "    elif mode == 'train': X_eval,  Y_eval = X_train, Y_train\n",
    "    \n",
    "    for i in range(0,len(x)):\n",
    "        x[i] = x[i] > 0.5\n",
    "    cols = []\n",
    "    for j in range(0, n):\n",
    "        if x[j] == 1:\n",
    "            cols.append(j)\n",
    "    z1_prime = extract_subset(X_train, cols)\n",
    "    z2_prime = extract_subset(X_eval, cols)\n",
    "    clf = GNB()\n",
    "    clf.fit(z1_prime, Y_train)\n",
    "    y_pred = clf.predict(z2_prime)\n",
    "    \n",
    "    acc = sklearn.metrics.accuracy_score(Y_eval,y_pred)\n",
    "    pre = sklearn.metrics.precision_score(Y_eval,y_pred)\n",
    "    fscore = sklearn.metrics.f1_score(Y_eval,y_pred)\n",
    "    recall = sklearn.metrics.recall_score(Y_eval,y_pred)\n",
    "    return acc,pre,fscore,recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialise(m,n):\n",
    "    for i in range(0,m):\n",
    "        for j in range(0,n):\n",
    "            x = randint(0,1)\n",
    "            bat_pos[i].append(x)\n",
    "            bat_vel[i].append(0)\n",
    "\n",
    "        init_rate_vector.append(random.uniform(0, 1))\n",
    "\n",
    "        bat_frequency.append(init_rate_vector[i])\n",
    "        bat_loudness.append(random.uniform(1,2))\n",
    "        bat_rate.append(init_rate_vector[i])\n",
    "        bat_fitness.append(-infinity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def core():\n",
    "#     initialise(m,n)\n",
    "#     global_fit = -infinity\n",
    "#     for t in range (0,T):\n",
    "#         print(\"T:\" , t)\n",
    "#         for i in range(0,m):\n",
    "#             accuracy,pre,fscore,recall = svm_calc_fitness(bat_pos[i])\n",
    "#             '''\n",
    "#             with open(\"dumpPerformanceBat_svm_kpi.txt\", \"a\") as text_file:\n",
    "#                 text_file.write(\"{} {} {} {} {}\".format(accuracy,pre,fscore,recall,global_fit) + \"\\n\")\n",
    "#             with open(\"dumpPerformanceBat_svm.txt\", \"a\") as text_file:\n",
    "#                 text_file.write(\"{} {} {} {}\".format(t,accuracy,bat_pos[i].count(1),global_fit)+\"\\n\")\n",
    "#             #print(\"t={} accuracy={} #features={} global_fit={}\".format(t,accuracy,bat_pos[i].count(1),global_fit))\n",
    "#             '''\n",
    "#             acc = accuracy\n",
    "\n",
    "#             rand = randint(0,1)\n",
    "#             if rand < bat_loudness[i] and acc > bat_fitness[i]:\n",
    "#                 bat_fitness[i]=acc\n",
    "#                 bat_loudness[i]= alpha * bat_loudness[i]\n",
    "#                 bat_rate[i]= init_rate_vector[i] * (1 - math.exp(-(gamma * t)))\n",
    "\n",
    "#         maxindex,maxfit = max(enumerate(bat_fitness), key=operator.itemgetter(1))\n",
    "\n",
    "#         if maxfit>global_fit :\n",
    "#             global_fit = maxfit\n",
    "#             global_bat_pos = bat_pos[maxindex]\n",
    "\n",
    "#         for i in range(0,m): # for each bat\n",
    "#             beta = random.uniform(0,1)\n",
    "#             rand = random.uniform(0,1)\n",
    "#             AvgA = sum(bat_loudness)/len(bat_loudness)\n",
    "\n",
    "#             if rand > bat_rate[i] :\n",
    "#                 for j in range(0,n):\n",
    "#                     bat_pos[i][j] = bat_pos[i][j] + ( epsilon * AvgA )\n",
    "#                     sigma = randint(0,1)\n",
    "#                     if sigma < (1/(1+math.exp(-bat_pos[i][j]))) :\n",
    "#                         bat_pos[i][j]=1\n",
    "#                     else :\n",
    "#                         bat_pos[i][j]= 0\n",
    "\n",
    "#             rand = random.uniform(0,1)\n",
    "#             if rand < bat_loudness[i] and bat_fitness[i] < global_fit :\n",
    "#                 for j in range (0,n):\n",
    "#                     bat_frequency[i] = fmin + (fmax-fmin)* beta\n",
    "#                     bat_vel[i][j] = bat_vel[i][j] + (global_bat_pos[j]-bat_pos[i][j]) * bat_frequency[i]\n",
    "#                     bat_pos[i][j] = bat_pos[i][j] + bat_vel[i][j]\n",
    "#                     sigma = random.uniform(0,1)\n",
    "#                     if sigma < (1 / (1 + math.exp(-bat_pos[i][j]))) :\n",
    "#                         bat_pos[i][j]=1\n",
    "#                     else :\n",
    "#                         bat_pos[i][j]=0\n",
    "#         with open(\"dumpPerformanceBat_rf.txt\", \"a\") as text_file:\n",
    "#             text_file.write(\"{} {} {} \".format(t,global_bat_pos.count(1),global_fit)+\"\\n\")\n",
    "        \n",
    "\n",
    "\n",
    "#     feature_vector = global_bat_pos\n",
    "#     return feature_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def BAT_algo():\n",
    "#     feature_vector = core()\n",
    "#     return feature_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f = BAT_algo()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneticAlgorithm():\n",
    "    \n",
    "    def __init__(self, X_train, X_dev, Y_train, Y_dev, number_bits_to_mutate = 25.0):\n",
    "        \n",
    "        \n",
    "        self.toolbox = base.Toolbox()\n",
    "        self.ind_mut_pb = float(number_bits_to_mutate / X_train.shape[1])\n",
    "        self.NGEN = 100\n",
    "        self.MUTPB = 0.2\n",
    "        self.CXPB = 0.5\n",
    "        self.POPULATION_SIZE = 70\n",
    "        self.NUMBER_TO_SELECT_FROM_POP = 35\n",
    "        self.init_pop = list()\n",
    "        self.X_train = X_train\n",
    "        self.X_dev = X_dev\n",
    "        self.Y_train = Y_train\n",
    "        self.Y_dev = Y_dev\n",
    "        \n",
    "    \n",
    "    def initialise_toolbox(self):\n",
    "        print('now initializing toolbox GA1')\n",
    "        # I want to maximize session overlap as well as length\n",
    "        creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
    "        # representing individual as a list\n",
    "        creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
    "        # individual will be a list of 0/1\n",
    "        self.toolbox.register(\"attr_bool\", random.randint, 0, 1)\n",
    "        IND_DIMENSIONALITY = self.X_train.shape[1]\n",
    "        # create template for individual\n",
    "        self.toolbox.register(\"individual\", tools.initRepeat, creator.Individual, self.toolbox.attr_bool, n=IND_DIMENSIONALITY)\n",
    "        #self.toolbox.register(\"individual\", tools.initIterate, creator.Individual, self.get_ind)\n",
    "        # create template for population\n",
    "        self.toolbox.register(\"population\", tools.initRepeat, list, self.toolbox.individual)\n",
    "        print('toolbox initialised')\n",
    "    \n",
    "    \n",
    "    def initialise_fitness_function(self):\n",
    "        print('building and registering the fitness function')\n",
    "        \n",
    "        def fitness(individual):\n",
    "            \n",
    "            \n",
    "            accuracy,pre,fscore,recall = rf_calc_fitness(individual)\n",
    "            return fscore,\n",
    "            \n",
    "        \n",
    "        self.toolbox.register(\"evaluate\", lambda individual: fitness(individual))\n",
    "        self.toolbox.register(\"mate\", tools.cxOnePoint)\n",
    "        self.toolbox.register(\"mutate\", tools.mutFlipBit, indpb=self.MUTPB)\n",
    "        self.toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
    "        \n",
    "        print('fitness function ready')\n",
    "    \n",
    "    def run_algorithm(self):\n",
    "        \n",
    "        self.initialise_toolbox()\n",
    "        self.initialise_fitness_function()\n",
    "        \n",
    "        print('mutation probability was calculated at %f' % self.ind_mut_pb)\n",
    "        print('running the algorithm')\n",
    "        toolbox = self.toolbox\n",
    "        # create a population of size n\n",
    "        pop = toolbox.population(n=self.POPULATION_SIZE)\n",
    "        \n",
    "        \n",
    "        for gen in range(self.NGEN):\n",
    "            # Select the next generation individuals\n",
    "            if gen%5 == 0:\n",
    "                print(gen)\n",
    "            offspring = toolbox.select(pop, len(pop))\n",
    "            \n",
    "            for ind in offspring:\n",
    "                if ind.fitness.valid:\n",
    "                    pass\n",
    "            # Clone the selected individuals\n",
    "            offspring = list(map(toolbox.clone, offspring))\n",
    "\n",
    "            # Apply crossover on the offspring\n",
    "            for child1, child2 in zip(offspring[::2], offspring[1::2]):\n",
    "                if random.random() < self.CXPB:\n",
    "                    #toolbox.mate(child1, child2)\n",
    "                    tools.cxUniform(child1, child2, 0.5)\n",
    "                    del child1.fitness.values\n",
    "                    del child2.fitness.values\n",
    "\n",
    "            # Apply mutation on the offspring\n",
    "            for mutant in offspring:\n",
    "                if random.random() < self.MUTPB:\n",
    "                    # print('now doing mutation')\n",
    "                    toolbox.mutate(mutant)\n",
    "                    del mutant.fitness.values\n",
    "\n",
    "            # Evaluate the individuals with an invalid fitness\n",
    "            invalid_ind = [ind for ind in offspring if not ind.fitness.valid]\n",
    "            fitnesses = toolbox.map(toolbox.evaluate, invalid_ind)\n",
    "            \n",
    "            added = 0\n",
    "            for ind, fit in zip(invalid_ind, fitnesses):\n",
    "                ind.fitness.values = fit\n",
    "                \n",
    "\n",
    "            # The population is entirely replaced by the offspring\n",
    "            pop[:] = offspring\n",
    "            top = tools.selBest(pop, k=self.NUMBER_TO_SELECT_FROM_POP)\n",
    "            \n",
    "            # Dump best individual to file\n",
    "            fittest = tools.selBest(pop, k=1)[0]\n",
    "            count = 0\n",
    "            for i in range(0, len(fittest)):\n",
    "                if fittest[i] == 1:\n",
    "                    count = count + 1\n",
    "            with open(\"GA_performance.txt\", \"a\") as text_file:\n",
    "                accuracy,prec,fscore,recall = rf_calc_fitness(fittest)\n",
    "                text_file.write(\"{} {}\".format(count,fittest.fitness.values[0])+\"\\n\")\n",
    "                print(count,accuracy,prec,fscore,recall,fittest.fitness.values[0])\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        max_fitness = float(\"-inf\")\n",
    "        \n",
    "        for individual in tools.selBest(pop, k=1):\n",
    "            if individual.fitness.valid:\n",
    "                if individual.fitness.values[0] > max_fitness:\n",
    "                    max_fitness = individual.fitness.values[0]\n",
    "                    fittest_individual = individual\n",
    "                    \n",
    "        count = 0\n",
    "        for i in range(0, len(fittest_individual)):\n",
    "            if fittest_individual[i] == 1:\n",
    "                count = count + 1        \n",
    "        \n",
    "        print(count, max_fitness)\n",
    "        return fittest_individual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ga = GeneticAlgorithm(X_train, X_dev, Y_train, Y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now initializing toolbox GA1\n",
      "toolbox initialised\n",
      "building and registering the fitness function\n",
      "fitness function ready\n",
      "mutation probability was calculated at 0.002940\n",
      "running the algorithm\n",
      "0\n",
      "4374 0.7676767676767676 0.7549295774647887 0.6997389033942558 0.6520681265206812 0.6997389033942558\n",
      "4220 0.7838383838383839 0.7855072463768116 0.7169312169312169 0.6593673965936739 0.7169312169312169\n",
      "4220 0.7838383838383839 0.7855072463768116 0.7169312169312169 0.6593673965936739 0.7169312169312169\n",
      "4371 0.7828282828282829 0.7784090909090909 0.7182175622542595 0.6666666666666666 0.7182175622542595\n",
      "4220 0.7888888888888889 0.7805555555555556 0.7289234760051881 0.683698296836983 0.7289234760051881\n",
      "5\n",
      "4296 0.7909090909090909 0.7931034482758621 0.7272727272727273 0.6715328467153284 0.7272727272727273\n",
      "4335 0.7929292929292929 0.7926136363636364 0.7313237221494102 0.6788321167883211 0.7313237221494102\n",
      "4335 0.7929292929292929 0.7926136363636364 0.7313237221494102 0.6788321167883211 0.7313237221494102\n",
      "4335 0.7929292929292929 0.7926136363636364 0.7313237221494102 0.6788321167883211 0.7313237221494102\n",
      "4300 0.795959595959596 0.7927170868347339 0.7369791666666666 0.6885644768856448 0.7369791666666666\n",
      "10\n",
      "4286 0.795959595959596 0.7894736842105263 0.7383419689119172 0.6934306569343066 0.7383419689119172\n",
      "4345 0.797979797979798 0.7955182072829131 0.7395833333333334 0.6909975669099757 0.7395833333333334\n",
      "4310 0.802020202020202 0.7994428969359332 0.7454545454545456 0.6982968369829684 0.7454545454545456\n",
      "4267 0.803030303030303 0.7934782608695652 0.7496790757381258 0.7104622871046229 0.7496790757381258\n",
      "4264 0.8141414141414142 0.8161559888579387 0.7610389610389611 0.7128953771289538 0.7610389610389611\n",
      "15\n",
      "4267 0.803030303030303 0.7934782608695652 0.7496790757381258 0.7104622871046229 0.7496790757381258\n",
      "4331 0.8080808080808081 0.8112676056338028 0.7519582245430809 0.7007299270072993 0.7519582245430809\n",
      "4317 0.8101010101010101 0.8194842406876791 0.7526315789473685 0.6958637469586375 0.7526315789473685\n",
      "4349 0.8161616161616162 0.8225352112676056 0.762402088772846 0.7104622871046229 0.762402088772846\n",
      "4349 0.8161616161616162 0.8225352112676056 0.762402088772846 0.7104622871046229 0.762402088772846\n",
      "20\n",
      "4349 0.8161616161616162 0.8225352112676056 0.762402088772846 0.7104622871046229 0.762402088772846\n",
      "4329 0.8131313131313131 0.8210227272727273 0.7575360419397117 0.7031630170316302 0.7575360419397117\n",
      "4346 0.8121212121212121 0.8099173553719008 0.7596899224806202 0.7153284671532847 0.7596899224806202\n",
      "4346 0.8121212121212121 0.8099173553719008 0.7596899224806202 0.7153284671532847 0.7596899224806202\n",
      "4346 0.8121212121212121 0.8099173553719008 0.7596899224806202 0.7153284671532847 0.7596899224806202\n",
      "25\n",
      "4346 0.8121212121212121 0.8099173553719008 0.7596899224806202 0.7153284671532847 0.7596899224806202\n",
      "4346 0.8121212121212121 0.8099173553719008 0.7596899224806202 0.7153284671532847 0.7596899224806202\n",
      "4329 0.8181818181818182 0.8217270194986073 0.7662337662337663 0.7177615571776156 0.7662337662337663\n",
      "4337 0.8161616161616162 0.8154269972451791 0.764857881136951 0.7201946472019465 0.764857881136951\n",
      "4337 0.8161616161616162 0.8154269972451791 0.764857881136951 0.7201946472019465 0.764857881136951\n",
      "30\n",
      "4351 0.8222222222222222 0.8236914600550964 0.7726098191214471 0.7274939172749392 0.7726098191214471\n",
      "4351 0.8222222222222222 0.8236914600550964 0.7726098191214471 0.7274939172749392 0.7726098191214471\n",
      "4337 0.8191919191919191 0.8152173913043478 0.7702182284980745 0.7299270072992701 0.7702182284980745\n",
      "4342 0.8212121212121212 0.8145161290322581 0.7739463601532567 0.7372262773722628 0.7739463601532567\n",
      "4333 0.8242424242424242 0.8264462809917356 0.7751937984496124 0.7299270072992701 0.7751937984496124\n",
      "35\n",
      "4333 0.8242424242424242 0.8264462809917356 0.7751937984496124 0.7299270072992701 0.7751937984496124\n",
      "4332 0.8262626262626263 0.8310249307479224 0.77720207253886 0.7299270072992701 0.77720207253886\n",
      "4332 0.8262626262626263 0.8310249307479224 0.77720207253886 0.7299270072992701 0.77720207253886\n",
      "4362 0.8252525252525252 0.8269230769230769 0.7767741935483872 0.732360097323601 0.7767741935483872\n",
      "4334 0.8262626262626263 0.8292011019283747 0.7777777777777779 0.732360097323601 0.7777777777777779\n",
      "40\n",
      "4362 0.8252525252525252 0.8269230769230769 0.7767741935483872 0.732360097323601 0.7767741935483872\n",
      "4362 0.8252525252525252 0.8269230769230769 0.7767741935483872 0.732360097323601 0.7767741935483872\n",
      "4362 0.8252525252525252 0.8269230769230769 0.7767741935483872 0.732360097323601 0.7767741935483872\n",
      "4324 0.8282828282828283 0.8301369863013699 0.7809278350515464 0.7372262773722628 0.7809278350515464\n",
      "4324 0.8282828282828283 0.8301369863013699 0.7809278350515464 0.7372262773722628 0.7809278350515464\n",
      "45\n",
      "4324 0.8282828282828283 0.8301369863013699 0.7809278350515464 0.7372262773722628 0.7809278350515464\n",
      "4324 0.8282828282828283 0.8301369863013699 0.7809278350515464 0.7372262773722628 0.7809278350515464\n",
      "4324 0.8282828282828283 0.8301369863013699 0.7809278350515464 0.7372262773722628 0.7809278350515464\n",
      "4324 0.8282828282828283 0.8301369863013699 0.7809278350515464 0.7372262773722628 0.7809278350515464\n",
      "4324 0.8282828282828283 0.8301369863013699 0.7809278350515464 0.7372262773722628 0.7809278350515464\n",
      "50\n",
      "4324 0.8282828282828283 0.8301369863013699 0.7809278350515464 0.7372262773722628 0.7809278350515464\n",
      "4324 0.8282828282828283 0.8301369863013699 0.7809278350515464 0.7372262773722628 0.7809278350515464\n",
      "4324 0.8282828282828283 0.8301369863013699 0.7809278350515464 0.7372262773722628 0.7809278350515464\n",
      "4324 0.8282828282828283 0.8301369863013699 0.7809278350515464 0.7372262773722628 0.7809278350515464\n",
      "4324 0.8282828282828283 0.8301369863013699 0.7809278350515464 0.7372262773722628 0.7809278350515464\n",
      "55\n",
      "4324 0.8282828282828283 0.8301369863013699 0.7809278350515464 0.7372262773722628 0.7809278350515464\n",
      "4324 0.8282828282828283 0.8301369863013699 0.7809278350515464 0.7372262773722628 0.7809278350515464\n",
      "4324 0.8282828282828283 0.8301369863013699 0.7809278350515464 0.7372262773722628 0.7809278350515464\n",
      "4324 0.8282828282828283 0.8301369863013699 0.7809278350515464 0.7372262773722628 0.7809278350515464\n",
      "4324 0.8282828282828283 0.8301369863013699 0.7809278350515464 0.7372262773722628 0.7809278350515464\n",
      "60\n",
      "4324 0.8282828282828283 0.8301369863013699 0.7809278350515464 0.7372262773722628 0.7809278350515464\n",
      "4324 0.8282828282828283 0.8301369863013699 0.7809278350515464 0.7372262773722628 0.7809278350515464\n",
      "4324 0.8282828282828283 0.8301369863013699 0.7809278350515464 0.7372262773722628 0.7809278350515464\n",
      "4324 0.8282828282828283 0.8301369863013699 0.7809278350515464 0.7372262773722628 0.7809278350515464\n",
      "4324 0.8282828282828283 0.8301369863013699 0.7809278350515464 0.7372262773722628 0.7809278350515464\n",
      "65\n",
      "4324 0.8282828282828283 0.8301369863013699 0.7809278350515464 0.7372262773722628 0.7809278350515464\n",
      "4324 0.8282828282828283 0.8301369863013699 0.7809278350515464 0.7372262773722628 0.7809278350515464\n",
      "4324 0.8282828282828283 0.8301369863013699 0.7809278350515464 0.7372262773722628 0.7809278350515464\n",
      "4324 0.8282828282828283 0.8301369863013699 0.7809278350515464 0.7372262773722628 0.7809278350515464\n",
      "4324 0.8282828282828283 0.8301369863013699 0.7809278350515464 0.7372262773722628 0.7809278350515464\n",
      "70\n",
      "4324 0.8282828282828283 0.8301369863013699 0.7809278350515464 0.7372262773722628 0.7809278350515464\n",
      "4324 0.8282828282828283 0.8301369863013699 0.7809278350515464 0.7372262773722628 0.7809278350515464\n",
      "4324 0.8282828282828283 0.8301369863013699 0.7809278350515464 0.7372262773722628 0.7809278350515464\n",
      "4324 0.8282828282828283 0.8301369863013699 0.7809278350515464 0.7372262773722628 0.7809278350515464\n",
      "4324 0.8282828282828283 0.8301369863013699 0.7809278350515464 0.7372262773722628 0.7809278350515464\n",
      "75\n",
      "4324 0.8282828282828283 0.8301369863013699 0.7809278350515464 0.7372262773722628 0.7809278350515464\n",
      "4324 0.8282828282828283 0.8301369863013699 0.7809278350515464 0.7372262773722628 0.7809278350515464\n",
      "4324 0.8282828282828283 0.8301369863013699 0.7809278350515464 0.7372262773722628 0.7809278350515464\n",
      "4324 0.8282828282828283 0.8301369863013699 0.7809278350515464 0.7372262773722628 0.7809278350515464\n",
      "4324 0.8282828282828283 0.8301369863013699 0.7809278350515464 0.7372262773722628 0.7809278350515464\n",
      "80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4324 0.8282828282828283 0.8301369863013699 0.7809278350515464 0.7372262773722628 0.7809278350515464\n",
      "4324 0.8282828282828283 0.8301369863013699 0.7809278350515464 0.7372262773722628 0.7809278350515464\n",
      "4324 0.8282828282828283 0.8301369863013699 0.7809278350515464 0.7372262773722628 0.7809278350515464\n",
      "4324 0.8282828282828283 0.8301369863013699 0.7809278350515464 0.7372262773722628 0.7809278350515464\n",
      "4324 0.8282828282828283 0.8301369863013699 0.7809278350515464 0.7372262773722628 0.7809278350515464\n",
      "85\n",
      "4324 0.8282828282828283 0.8301369863013699 0.7809278350515464 0.7372262773722628 0.7809278350515464\n",
      "4324 0.8282828282828283 0.8301369863013699 0.7809278350515464 0.7372262773722628 0.7809278350515464\n",
      "4324 0.8282828282828283 0.8301369863013699 0.7809278350515464 0.7372262773722628 0.7809278350515464\n",
      "4324 0.8282828282828283 0.8301369863013699 0.7809278350515464 0.7372262773722628 0.7809278350515464\n",
      "4324 0.8282828282828283 0.8301369863013699 0.7809278350515464 0.7372262773722628 0.7809278350515464\n",
      "90\n",
      "4324 0.8282828282828283 0.8301369863013699 0.7809278350515464 0.7372262773722628 0.7809278350515464\n",
      "4324 0.8282828282828283 0.8301369863013699 0.7809278350515464 0.7372262773722628 0.7809278350515464\n",
      "4324 0.8282828282828283 0.8301369863013699 0.7809278350515464 0.7372262773722628 0.7809278350515464\n",
      "4324 0.8282828282828283 0.8301369863013699 0.7809278350515464 0.7372262773722628 0.7809278350515464\n",
      "4324 0.8282828282828283 0.8301369863013699 0.7809278350515464 0.7372262773722628 0.7809278350515464\n",
      "95\n",
      "4324 0.8282828282828283 0.8301369863013699 0.7809278350515464 0.7372262773722628 0.7809278350515464\n",
      "4324 0.8282828282828283 0.8301369863013699 0.7809278350515464 0.7372262773722628 0.7809278350515464\n",
      "4324 0.8282828282828283 0.8301369863013699 0.7809278350515464 0.7372262773722628 0.7809278350515464\n",
      "4324 0.8282828282828283 0.8301369863013699 0.7809278350515464 0.7372262773722628 0.7809278350515464\n",
      "4324 0.8282828282828283 0.8301369863013699 0.7809278350515464 0.7372262773722628 0.7809278350515464\n",
      "4324 0.7809278350515464\n"
     ]
    }
   ],
   "source": [
    "fittest_individual = ga.run_algorithm()\n",
    "# takes ~30s per generation (for population of size 70)\n",
    "# total time ~1hr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'01000001100100011111011100101111111010000011001011010011101010111100110001010111110011001000111101110101100110010001101111001110110000011000000110010111011000110001110011101101111101010011111001011010001111010000010111011011110000100101101100111011010110010101101101110110110001001001101101111111011000011011010010010001101101100110011111110110010110001111110101000011010100110010100010010000100110110111001010000111110101000101101110010001001100110101011011110010010001000110001010101011000011111110111011111001101000000010011111100100110100001100000001010101000110101001110000010001011111100010101110001010111101000101101001001100101010000001011111111011011000011101100001000000010010111110110101001000110000011000110011100011010011000110001110011001001010101111101101001111010010000111011010011000110110011010100110110110011111000110100011111100100100110100010011111111001100010001001011100101110111110011011001001011010111000100101111100111110001111000010101000100101101101101100101101011011011010111010000110110001111011110010110001000010011010111001110101011001011000011111011011000011110000101100001110010101111011001111100000001101101100001101010100000000001100010100001110001100101010110010100100001110101111110111100101100011010011001101000001010110101011101001101100110100001111010111000111001000101110101100010100010111000011010000100100100110101011001000100001001001000101000110000000010010101001011101100101010111000011011110110000111010101111001110011100001010000010101100001000111010010100101010101101001110100011111010000110100001011011011111010000000001100001100001010011000001111110011011110100111011010110101111000000111000111110010111100010101100101111100110111110101110111100000100001011000111101111100011010110000000000110000011000001111000110111000010000011010001110000110001010000011100001111001110000011110010001010000010101100111001011011010010110001000111010011010110101101010111001011110001101111100000100011100001000010010000110001100010111000111100101001110001011110010101100111111000011000111011010101111101011000000110010010111110111010110101110010101010100110011010100011000010110101111010101000110010111010111001011101000000000001101000100000001101001101011011001100100001100110110111010100111001010001010111010011011100001110011100110111110010001011100011000100001101101100111110010000111110100110101001111010010010111001111111011011001101100011100101010111010101001001011001001001000101111101110011100101001101101010011110010001101111010000010111100011111001011011001001011110110111110001011110111111100010010000010001101101000011101001001001101001110000001111000100111010101010101000110110111001101010001010000000100100111110000100100001000010101010001000101101111100000100101001010100100000100010010101011000100000010010100101111101010110100101001101101111101001100011000100011010100110100110101000001100100111101010111100111011111000101001110001000111001111100101010001001011000011111101101011101001111110011000000000001100110111100100101100101100001011010010000101100111100111001101110001011011000111101000110111001101101011100011111111100111100011000010000101010001110011101110110101011010010111000010101101100010001011000100000001101111001011011101011110110010010000011100101000111110001100010111110011001000011110001110001110101010010011010010010010000000000100001010100001010100111100001100101111000111100100100111001011110000101010001110100100011000110100011001100111011010111100110010111000100001100001110001101000001111011111000100001101100000110100010100000101000011100111111111010110101101011110111011110010011010100110101100011111000001011001110001110000100100101101000110111111010010100011110100100110010011010111001110001111110101001101011010011011110010011111010111111011000011010010101011100101011000110000010011101100111001111101110011100011010100111110010111101100101000010010000011100000001001001111100011011101010000000000101110010111110111101111001100100100001110100001101001000110001001010011011111101000101000101110011101010011000111011100000101101000111101111100001100100101100011011001100101011011100010100100101111000001101011101010011001000101100011010111001000111110001000001010000000101100110110101101100101110000101110110101101011101100001111010011110100101101101111100101111110101111000101100011100101111111011101010110000011111110011111000100010000011110101010010000011010111111101100101101001101001111011101000001001111110110110101000111111110111100100001110110110100001111110011001000110001010010001001101001110001111010010100111000000111011110101111110011111011101001110000100110100100111101101010011010001001101010000010011000011001100011110000011111110001000010111001100011011111010110001000110110000001101110101101110100111001001101110000010011001000011110110010110001111001110011110010111011101011000101101011001111101011000001000000000010101000110001110000101000000010000010111011110111100000110110101001110011100100000010111011001011010110000001111111011110001000100000001011010000101001101111010111101101101110010011001100111111111111100001011010000110010100111111100001101111001110100011110101001011011101010101111010001011001010001011010101000001101000000000011111111110000101111011000000101001010101110000111111001101110110111001011001101010110100100011101101010100000001110111100111000010010010111100111010010011011010110110110000110101011101111100001001110100011101011011111011111110011001000011101101100000001111000110010111100001101000111010110100100100101101100010101000001010001100010000011010111000110110010011100011110100101000101100110100100101111011000111011001100011001110101111001010100000110011101010000101110101010111000000010110100111000100000010011111110110001111011110011100001101001111110011100100100111111100101110011100000111001010111001101100010101101001010000010101101100001000001011100000111010000000000111100110110000001100001111110001111001101011001010010100011010001101100100110011110011001001110001010011001110011011000101101000010100111011011111101011100001101100010110101011000110111110000100010001101111000111000010111010011101110000110001100001101101001010111110010011001001100011001110000110100100101110111100111100111001111011001010010010011101111011110001011111010000111011011010101100111110010111011100010100011001100000111101101100001000011111011011011000111010001101000101100111101001011000101101011100010011101001101011100010001010010111111011001000010100110011100011110001010011100010111001111000110100011100101000100110100110011011110010010010110000111001111110010111010010000101001100100111101010101101111100110111001110100110101011011001111011011100001010110110100110111111000101011001101010110000100111011110000011110000101110010110000110000101010000101101110101101110001110111110110100001000111010010111110110000101111101011000100100101110111111100000010011011011111100111000111111010101001011110100101100011000110001001111000000101010100100100100101101100100001001111110011111101011010110111100101111010110110011101001110100000110001001001001100100110100100010010110000100100101011101010000101101110110101101111001101001100010000111100011100001111110011001010100001000101111111101110101111111000110111101001110010001011001000110110100011100111011001100001100111011101010100010100100101000000010001011100000001100000111111000101110011011001110010011100110011010110001011001011000011110010000011110110110101000000001010001110100111011110100011011011100110110001000011100001000011101001100101010001011111110100001000000101100111011111110010011010101101110001110011101111111110101101001011101111110111110011010110001111011110101110110001110111100100111101001011100011001110110111001010100100011101000111000001001111101011000100110000010100101111010100110111000111110001010000110010101100001011110001111100001000000111001001110100010000110111111101111111100101110010001010101101101110001110010011110101001100000010111101101010001100111011011110000010100011010110010110010100001001110101011100010001111000111011101011011111101111111000001101011110111011000011110110000100001111101010010110000001111000000111010010101001011001110011100101001111010100101010000001111111000111010001101000110111001010101110110010101101000100100001000101000110010111111101101001011001001101111011111101110010001101101001001101110110110011001101010110011010000000110001101011000000100000001100011111000111100100011111001000111111011111100100110101110100000010110010110001001010101111111011101100010000111100111011110100111010010100101111000111010110110100001011010010111000011101001001111000101001111100'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fittest_individual # List[Boolean]\n",
    "''.join([str(int(x)) for x in fittest_individual])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8282828282828283,\n",
       " 0.8301369863013699,\n",
       " 0.7809278350515464,\n",
       " 0.7372262773722628)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# devset\n",
    "acc, pre, fscore, recall = rf_calc_fitness(fittest_individual)\n",
    "acc, pre, fscore, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7983539094650206,\n",
       " 0.7906542056074767,\n",
       " 0.7115222876366695,\n",
       " 0.6467889908256881)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testset\n",
    "acc, pre, fscore, recall = rf_calc_fitness(fittest_individual, mode='test')\n",
    "acc, pre, fscore, recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code Flow\n",
    "- Feature extraction from the corpus (uni, bi, tri, tf-idf, lda, pos, nrc)\n",
    "- GA (meta-heuristic) for feature selection\n",
    "  - population of individuals, where each individual corresponds to a bitmask of features to select\n",
    "  - individuals evolve over the generations by cross-over and mutation\n",
    "  - fitness of individuals is evaluated using F1 score (this score is calculated on devset by fitting the model with a small amount of trainset for guiding GA)\n",
    "  - after GA finishes, we end up we the fittest individual ie the optimal feature set (denoted by a bitmask) (giving a good reduction of 50%)\n",
    "- Finally we train our model on the complete training set based on the selected features and evaluate it on testset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
