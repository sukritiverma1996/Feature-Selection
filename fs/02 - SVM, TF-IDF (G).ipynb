{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "from random import randint\n",
    "import random\n",
    "import math\n",
    "from collections import defaultdict\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import svm\n",
    "import operator\n",
    "import sklearn.metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "from sklearn.naive_bayes import GaussianNB as GNB\n",
    "from pandas import DataFrame, read_csv\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from deap import creator, base, tools, algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         Description  Category\n",
      "0  Was walking along crowded street, holding mums...         1\n",
      "1  This incident took place in the evening.I was ...         0\n",
      "2  I WAS WAITING FOR THE BUS. A MAN CAME ON A BIK...         0\n",
      "3                 Incident happened inside the train         0\n",
      "4  I witnessed an incident when a chain was bruta...         0\n"
     ]
    }
   ],
   "source": [
    "file1 = '../../data/safecity/binary/groping/train.csv'\n",
    "df = pd.read_csv(file1)\n",
    "print(df.head())\n",
    "\n",
    "corpus = list(df[\"Description\"])\n",
    "target = list(df[\"Category\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# infinity = float(\"inf\") #sentinel maximum value\n",
    "# m = 70 #no of bats (50-70)\n",
    "# T = 100 # no of iterations(100)\n",
    "\n",
    "# bat_pos = defaultdict(list)\n",
    "# bat_vel = defaultdict(list)\n",
    "# bat_loudness = []\n",
    "# bat_rate = []\n",
    "# bat_fitness = []\n",
    "# bat_frequency = []\n",
    "\n",
    "# global_bat_pos = []\n",
    "# init_rate_vector = []\n",
    "# feature_vector = []\n",
    "\n",
    "# #hyperparameters\n",
    "# alpha = 0.9\n",
    "# gamma = 0.9\n",
    "# epsilon = random.uniform(-1,1)\n",
    "# fmin=0\n",
    "# fmax =1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7201, 8504)\n",
      "['00', '000', '00am', '00pm', '01', '03', '0300', '05', '06', '0740', '0800am', '0830', '08826862360', '0900', '0930', '0f', '10', '100', '1000', '1000am', '1011am', '1012', '1015', '1030', '1030am', '1030ish', '1030pm', '1050', '10pm', '10th', '11', '1115', '1130', '1139', '1150', '11am', '11h', '11th', '12', '1213', '1214', '1230', '1245', '12th', '12yearold', '12years', '12yrs', '13', '1314', '13th']\n",
      "8504\n",
      "                                         Description  Category\n",
      "0  Buses approaching to this place is highly unsafe.         1\n",
      "1                        a man was commenting at me.         0\n",
      "2                                    in a share auto         1\n",
      "3  I was coming out of a club at night with a few...         0\n",
      "4  One of my friends was molested in the crowd. T...         1\n",
      "(990, 8504)\n",
      "['00', '000', '00am', '00pm', '01', '03', '0300', '05', '06', '0740', '0800am', '0830', '08826862360', '0900', '0930', '0f', '10', '100', '1000', '1000am', '1011am', '1012', '1015', '1030', '1030am', '1030ish', '1030pm', '1050', '10pm', '10th', '11', '1115', '1130', '1139', '1150', '11am', '11h', '11th', '12', '1213', '1214', '1230', '1245', '12th', '12yearold', '12years', '12yrs', '13', '1314', '13th']\n",
      "8504\n",
      "                                         Description  Category\n",
      "0  During morning, a woman was walking by and thi...         0\n",
      "1  A man tried to brush his penis off of a woman'...         1\n",
      "2  This happened to a fellow passenger of mine tr...         0\n",
      "3                                             ogling         0\n",
      "4  When I was returning my home after finishing m...         1\n",
      "(1701, 8504)\n",
      "['00', '000', '00am', '00pm', '01', '03', '0300', '05', '06', '0740', '0800am', '0830', '08826862360', '0900', '0930', '0f', '10', '100', '1000', '1000am', '1011am', '1012', '1015', '1030', '1030am', '1030ish', '1030pm', '1050', '10pm', '10th', '11', '1115', '1130', '1139', '1150', '11am', '11h', '11th', '12', '1213', '1214', '1230', '1245', '12th', '12yearold', '12years', '12yrs', '13', '1314', '13th']\n",
      "8504\n"
     ]
    }
   ],
   "source": [
    "#do once\n",
    "# nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 1), stop_words=stop_words)\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "print(X.shape)\n",
    "print(vectorizer.get_feature_names()[0:50])\n",
    "print(len(vectorizer.get_feature_names()))\n",
    "\n",
    "X_train = X\n",
    "Y_train = target\n",
    "\n",
    "file2 = '../../data/safecity/binary/groping/dev.csv'\n",
    "df_dev = pd.read_csv(file2)\n",
    "print(df_dev.head())\n",
    "corpus_dev = list(df_dev[\"Description\"])\n",
    "target_dev = list(df_dev[\"Category\"])\n",
    "X_dev = vectorizer.transform(corpus_dev)\n",
    "print(X_dev.shape)\n",
    "print(vectorizer.get_feature_names()[0:50])\n",
    "print(len(vectorizer.get_feature_names()))\n",
    "Y_dev = target_dev\n",
    "\n",
    "file3 = '../../data/safecity/binary/groping/test.csv'\n",
    "df_test = pd.read_csv(file3)\n",
    "print(df_test.head())\n",
    "corpus_test = list(df_test[\"Description\"])\n",
    "target_test = list(df_test[\"Category\"])\n",
    "X_test = vectorizer.transform(corpus_test)\n",
    "print(X_test.shape)\n",
    "print(vectorizer.get_feature_names()[0:50])\n",
    "print(len(vectorizer.get_feature_names()))\n",
    "Y_test = target_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7201, 8504) (990, 8504)\n"
     ]
    }
   ],
   "source": [
    "z1, z2 = X_train, X_dev\n",
    "print(z1.shape, z2.shape)\n",
    "n = z1.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#auxillary  functions\n",
    "def extract_subset(z,cols):\n",
    "    return z[:,cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_calc_fitness(x, mode=None): # SVM classifier\n",
    "    if mode in (None, 'dev'): X_eval, Y_eval = X_dev, Y_dev\n",
    "    elif mode == 'test': X_eval, Y_eval = X_test, Y_test\n",
    "    elif mode == 'train': X_eval,  Y_eval = X_train, Y_train\n",
    "        \n",
    "    for i in range(0,len(x)):\n",
    "        x[i] = x[i] > 0.5\n",
    "    cols = []\n",
    "    for j in range(0, n):\n",
    "        if x[j] == 1:\n",
    "            cols.append(j)\n",
    "    z1_prime = extract_subset(X_train, cols)\n",
    "    z2_prime = extract_subset(X_eval, cols)\n",
    "    clf = svm.LinearSVC(C=1.0)\n",
    "    clf.fit(z1_prime, Y_train)\n",
    "    y_pred = clf.predict(z2_prime)\n",
    "    \n",
    "    acc = sklearn.metrics.accuracy_score(Y_eval,y_pred)\n",
    "    pre = sklearn.metrics.precision_score(Y_eval,y_pred)\n",
    "    fscore = sklearn.metrics.f1_score(Y_eval,y_pred)\n",
    "    recall = sklearn.metrics.recall_score(Y_eval,y_pred)\n",
    "    return acc,pre,fscore,recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf_calc_fitness(x, mode=None): # RF classifier\n",
    "    if mode in (None, 'dev'): X_eval, Y_eval = X_dev, Y_dev\n",
    "    elif mode == 'test': X_eval, Y_eval = X_test, Y_test\n",
    "    elif mode == 'train': X_eval,  Y_eval = X_train, Y_train\n",
    "        \n",
    "    for i in range(0,len(x)):\n",
    "        x[i] = x[i] > 0.5\n",
    "    cols = []\n",
    "    for j in range(0, n):\n",
    "        if x[j] == 1:\n",
    "            cols.append(j)\n",
    "    z1_prime = extract_subset(X_train, cols)\n",
    "    z2_prime = extract_subset(X_eval, cols)\n",
    "    clf = RandomForestClassifier(n_jobs=2,random_state=0)\n",
    "    clf.fit(z1_prime, Y_train)\n",
    "    y_pred = clf.predict(z2_prime)\n",
    "    \n",
    "    acc = sklearn.metrics.accuracy_score(Y_eval,y_pred)\n",
    "    pre = sklearn.metrics.precision_score(Y_eval,y_pred)\n",
    "    fscore = sklearn.metrics.f1_score(Y_eval,y_pred)\n",
    "    recall = sklearn.metrics.recall_score(Y_eval,y_pred)\n",
    "    return acc,pre,fscore,recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_calc_fitness(x, mode=None): # KNN classifier\n",
    "    if mode in (None, 'dev'): X_eval, Y_eval = X_dev, Y_dev\n",
    "    elif mode == 'test': X_eval, Y_eval = X_test, Y_test\n",
    "    elif mode == 'train': X_eval,  Y_eval = X_train, Y_train\n",
    "\n",
    "    for i in range(0,len(x)):\n",
    "        x[i] = x[i] > 0.5\n",
    "    cols = []\n",
    "    for j in range(0, n):\n",
    "        if x[j] == 1:\n",
    "            cols.append(j)\n",
    "    z1_prime = extract_subset(X_train, cols)\n",
    "    z2_prime = extract_subset(X_eval, cols)\n",
    "    clf = KNN(3,weights='uniform')\n",
    "    clf.fit(z1_prime, Y_train)\n",
    "    y_pred = clf.predict(z2_prime)\n",
    "    \n",
    "    acc = sklearn.metrics.accuracy_score(Y_eval,y_pred)\n",
    "    pre = sklearn.metrics.precision_score(Y_eval,y_pred)\n",
    "    fscore = sklearn.metrics.f1_score(Y_eval,y_pred)\n",
    "    recall = sklearn.metrics.recall_score(Y_eval,y_pred)\n",
    "    return acc,pre,fscore,recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nb_calc_fitness(x, mode=None): # Gaussian NB (Naive Bayes) classifier\n",
    "    if mode in (None, 'dev'): X_eval, Y_eval = X_dev, Y_dev\n",
    "    elif mode == 'test': X_eval, Y_eval = X_test, Y_test\n",
    "    elif mode == 'train': X_eval,  Y_eval = X_train, Y_train\n",
    "    \n",
    "    for i in range(0,len(x)):\n",
    "        x[i] = x[i] > 0.5\n",
    "    cols = []\n",
    "    for j in range(0, n):\n",
    "        if x[j] == 1:\n",
    "            cols.append(j)\n",
    "    z1_prime = extract_subset(X_train, cols)\n",
    "    z2_prime = extract_subset(X_eval, cols)\n",
    "    clf = GNB()\n",
    "    clf.fit(z1_prime, Y_train)\n",
    "    y_pred = clf.predict(z2_prime)\n",
    "    \n",
    "    acc = sklearn.metrics.accuracy_score(Y_eval,y_pred)\n",
    "    pre = sklearn.metrics.precision_score(Y_eval,y_pred)\n",
    "    fscore = sklearn.metrics.f1_score(Y_eval,y_pred)\n",
    "    recall = sklearn.metrics.recall_score(Y_eval,y_pred)\n",
    "    return acc,pre,fscore,recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialise(m,n):\n",
    "    for i in range(0,m):\n",
    "        for j in range(0,n):\n",
    "            x = randint(0,1)\n",
    "            bat_pos[i].append(x)\n",
    "            bat_vel[i].append(0)\n",
    "\n",
    "        init_rate_vector.append(random.uniform(0, 1))\n",
    "\n",
    "        bat_frequency.append(init_rate_vector[i])\n",
    "        bat_loudness.append(random.uniform(1,2))\n",
    "        bat_rate.append(init_rate_vector[i])\n",
    "        bat_fitness.append(-infinity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def core():\n",
    "#     initialise(m,n)\n",
    "#     global_fit = -infinity\n",
    "#     for t in range (0,T):\n",
    "#         print(\"T:\" , t)\n",
    "#         for i in range(0,m):\n",
    "#             accuracy,pre,fscore,recall = svm_calc_fitness(bat_pos[i])\n",
    "#             '''\n",
    "#             with open(\"dumpPerformanceBat_svm_kpi.txt\", \"a\") as text_file:\n",
    "#                 text_file.write(\"{} {} {} {} {}\".format(accuracy,pre,fscore,recall,global_fit) + \"\\n\")\n",
    "#             with open(\"dumpPerformanceBat_svm.txt\", \"a\") as text_file:\n",
    "#                 text_file.write(\"{} {} {} {}\".format(t,accuracy,bat_pos[i].count(1),global_fit)+\"\\n\")\n",
    "#             #print(\"t={} accuracy={} #features={} global_fit={}\".format(t,accuracy,bat_pos[i].count(1),global_fit))\n",
    "#             '''\n",
    "#             acc = accuracy\n",
    "\n",
    "#             rand = randint(0,1)\n",
    "#             if rand < bat_loudness[i] and acc > bat_fitness[i]:\n",
    "#                 bat_fitness[i]=acc\n",
    "#                 bat_loudness[i]= alpha * bat_loudness[i]\n",
    "#                 bat_rate[i]= init_rate_vector[i] * (1 - math.exp(-(gamma * t)))\n",
    "\n",
    "#         maxindex,maxfit = max(enumerate(bat_fitness), key=operator.itemgetter(1))\n",
    "\n",
    "#         if maxfit>global_fit :\n",
    "#             global_fit = maxfit\n",
    "#             global_bat_pos = bat_pos[maxindex]\n",
    "\n",
    "#         for i in range(0,m): # for each bat\n",
    "#             beta = random.uniform(0,1)\n",
    "#             rand = random.uniform(0,1)\n",
    "#             AvgA = sum(bat_loudness)/len(bat_loudness)\n",
    "\n",
    "#             if rand > bat_rate[i] :\n",
    "#                 for j in range(0,n):\n",
    "#                     bat_pos[i][j] = bat_pos[i][j] + ( epsilon * AvgA )\n",
    "#                     sigma = randint(0,1)\n",
    "#                     if sigma < (1/(1+math.exp(-bat_pos[i][j]))) :\n",
    "#                         bat_pos[i][j]=1\n",
    "#                     else :\n",
    "#                         bat_pos[i][j]= 0\n",
    "\n",
    "#             rand = random.uniform(0,1)\n",
    "#             if rand < bat_loudness[i] and bat_fitness[i] < global_fit :\n",
    "#                 for j in range (0,n):\n",
    "#                     bat_frequency[i] = fmin + (fmax-fmin)* beta\n",
    "#                     bat_vel[i][j] = bat_vel[i][j] + (global_bat_pos[j]-bat_pos[i][j]) * bat_frequency[i]\n",
    "#                     bat_pos[i][j] = bat_pos[i][j] + bat_vel[i][j]\n",
    "#                     sigma = random.uniform(0,1)\n",
    "#                     if sigma < (1 / (1 + math.exp(-bat_pos[i][j]))) :\n",
    "#                         bat_pos[i][j]=1\n",
    "#                     else :\n",
    "#                         bat_pos[i][j]=0\n",
    "#         with open(\"dumpPerformanceBat_rf.txt\", \"a\") as text_file:\n",
    "#             text_file.write(\"{} {} {} \".format(t,global_bat_pos.count(1),global_fit)+\"\\n\")\n",
    "        \n",
    "\n",
    "\n",
    "#     feature_vector = global_bat_pos\n",
    "#     return feature_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def BAT_algo():\n",
    "#     feature_vector = core()\n",
    "#     return feature_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f = BAT_algo()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneticAlgorithm():\n",
    "    \n",
    "    def __init__(self, X_train, X_dev, Y_train, Y_dev, number_bits_to_mutate = 25.0):\n",
    "        \n",
    "        \n",
    "        self.toolbox = base.Toolbox()\n",
    "        self.ind_mut_pb = float(number_bits_to_mutate / X_train.shape[1])\n",
    "        self.NGEN = 100\n",
    "        self.MUTPB = 0.2\n",
    "        self.CXPB = 0.5\n",
    "        self.POPULATION_SIZE = 70\n",
    "        self.NUMBER_TO_SELECT_FROM_POP = 35\n",
    "        self.init_pop = list()\n",
    "        self.X_train = X_train\n",
    "        self.X_dev = X_dev\n",
    "        self.Y_train = Y_train\n",
    "        self.Y_dev = Y_dev\n",
    "        \n",
    "    \n",
    "    def initialise_toolbox(self):\n",
    "        print('now initializing toolbox GA1')\n",
    "        # I want to maximize session overlap as well as length\n",
    "        creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
    "        # representing individual as a list\n",
    "        creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
    "        # individual will be a list of 0/1\n",
    "        self.toolbox.register(\"attr_bool\", random.randint, 0, 1)\n",
    "        IND_DIMENSIONALITY = self.X_train.shape[1]\n",
    "        # create template for individual\n",
    "        self.toolbox.register(\"individual\", tools.initRepeat, creator.Individual, self.toolbox.attr_bool, n=IND_DIMENSIONALITY)\n",
    "        #self.toolbox.register(\"individual\", tools.initIterate, creator.Individual, self.get_ind)\n",
    "        # create template for population\n",
    "        self.toolbox.register(\"population\", tools.initRepeat, list, self.toolbox.individual)\n",
    "        print('toolbox initialised')\n",
    "    \n",
    "    \n",
    "    def initialise_fitness_function(self):\n",
    "        print('building and registering the fitness function')\n",
    "        \n",
    "        def fitness(individual):\n",
    "            \n",
    "            \n",
    "            accuracy,pre,fscore,recall = svm_calc_fitness(individual)\n",
    "            return fscore,\n",
    "            \n",
    "        \n",
    "        self.toolbox.register(\"evaluate\", lambda individual: fitness(individual))\n",
    "        self.toolbox.register(\"mate\", tools.cxOnePoint)\n",
    "        self.toolbox.register(\"mutate\", tools.mutFlipBit, indpb=self.MUTPB)\n",
    "        self.toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
    "        \n",
    "        print('fitness function ready')\n",
    "    \n",
    "    def run_algorithm(self):\n",
    "        \n",
    "        self.initialise_toolbox()\n",
    "        self.initialise_fitness_function()\n",
    "        \n",
    "        print('mutation probability was calculated at %f' % self.ind_mut_pb)\n",
    "        print('running the algorithm')\n",
    "        toolbox = self.toolbox\n",
    "        # create a population of size n\n",
    "        pop = toolbox.population(n=self.POPULATION_SIZE)\n",
    "        \n",
    "        \n",
    "        for gen in range(self.NGEN):\n",
    "            # Select the next generation individuals\n",
    "            if gen%5 == 0:\n",
    "                print(gen)\n",
    "            offspring = toolbox.select(pop, len(pop))\n",
    "            \n",
    "            for ind in offspring:\n",
    "                if ind.fitness.valid:\n",
    "                    pass\n",
    "            # Clone the selected individuals\n",
    "            offspring = list(map(toolbox.clone, offspring))\n",
    "\n",
    "            # Apply crossover on the offspring\n",
    "            for child1, child2 in zip(offspring[::2], offspring[1::2]):\n",
    "                if random.random() < self.CXPB:\n",
    "                    #toolbox.mate(child1, child2)\n",
    "                    tools.cxUniform(child1, child2, 0.5)\n",
    "                    del child1.fitness.values\n",
    "                    del child2.fitness.values\n",
    "\n",
    "            # Apply mutation on the offspring\n",
    "            for mutant in offspring:\n",
    "                if random.random() < self.MUTPB:\n",
    "                    # print('now doing mutation')\n",
    "                    toolbox.mutate(mutant)\n",
    "                    del mutant.fitness.values\n",
    "\n",
    "            # Evaluate the individuals with an invalid fitness\n",
    "            invalid_ind = [ind for ind in offspring if not ind.fitness.valid]\n",
    "            fitnesses = toolbox.map(toolbox.evaluate, invalid_ind)\n",
    "            \n",
    "            added = 0\n",
    "            for ind, fit in zip(invalid_ind, fitnesses):\n",
    "                ind.fitness.values = fit\n",
    "                \n",
    "\n",
    "            # The population is entirely replaced by the offspring\n",
    "            pop[:] = offspring\n",
    "            top = tools.selBest(pop, k=self.NUMBER_TO_SELECT_FROM_POP)\n",
    "            \n",
    "            # Dump best individual to file\n",
    "            fittest = tools.selBest(pop, k=1)[0]\n",
    "            count = 0\n",
    "            for i in range(0, len(fittest)):\n",
    "                if fittest[i] == 1:\n",
    "                    count = count + 1\n",
    "            with open(\"GA_performance.txt\", \"a\") as text_file:\n",
    "                accuracy,prec,fscore,recall = svm_calc_fitness(fittest)\n",
    "                text_file.write(\"{} {}\".format(count,fittest.fitness.values[0])+\"\\n\")\n",
    "                print(count,accuracy,prec,fscore,recall,fittest.fitness.values[0])\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        max_fitness = float(\"-inf\")\n",
    "        \n",
    "        for individual in tools.selBest(pop, k=1):\n",
    "            if individual.fitness.valid:\n",
    "                if individual.fitness.values[0] > max_fitness:\n",
    "                    max_fitness = individual.fitness.values[0]\n",
    "                    fittest_individual = individual\n",
    "                    \n",
    "        count = 0\n",
    "        for i in range(0, len(fittest_individual)):\n",
    "            if fittest_individual[i] == 1:\n",
    "                count = count + 1        \n",
    "        \n",
    "        print(count, max_fitness)\n",
    "        return fittest_individual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ga = GeneticAlgorithm(X_train, X_dev, Y_train, Y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now initializing toolbox GA1\n",
      "toolbox initialised\n",
      "building and registering the fitness function\n",
      "fitness function ready\n",
      "mutation probability was calculated at 0.002940\n",
      "running the algorithm\n",
      "0\n",
      "4193 0.8575757575757575 0.8502415458937198 0.7139959432048681 0.6153846153846154 0.7139959432048681\n",
      "4193 0.8575757575757575 0.8502415458937198 0.7139959432048681 0.6153846153846154 0.7139959432048681\n",
      "4252 0.8606060606060606 0.8627450980392157 0.7183673469387755 0.6153846153846154 0.7183673469387755\n",
      "4209 0.8626262626262626 0.8640776699029126 0.7235772357723578 0.6223776223776224 0.7235772357723578\n",
      "4204 0.8666666666666667 0.8701923076923077 0.7327935222672065 0.6328671328671329 0.7327935222672065\n",
      "5\n",
      "4259 0.8686868686868687 0.8861386138613861 0.7336065573770492 0.6258741258741258 0.7336065573770492\n",
      "4280 0.8696969696969697 0.8651162790697674 0.7425149700598802 0.6503496503496503 0.7425149700598802\n",
      "4198 0.8717171717171717 0.8994974874371859 0.7381443298969071 0.6258741258741258 0.7381443298969071\n",
      "4277 0.8727272727272727 0.8883495145631068 0.7439024390243903 0.6398601398601399 0.7439024390243903\n",
      "4254 0.8767676767676768 0.9019607843137255 0.7510204081632654 0.6433566433566433 0.7510204081632654\n",
      "10\n",
      "4208 0.8787878787878788 0.915 0.7530864197530864 0.6398601398601399 0.7530864197530864\n",
      "4176 0.8757575757575757 0.8899521531100478 0.7515151515151514 0.6503496503496503 0.7515151515151514\n",
      "4215 0.8767676767676768 0.8942307692307693 0.7530364372469636 0.6503496503496503 0.7530364372469636\n",
      "4192 0.8787878787878788 0.8952380952380953 0.7580645161290321 0.6573426573426573 0.7580645161290321\n",
      "4192 0.8787878787878788 0.8952380952380953 0.7580645161290321 0.6573426573426573 0.7580645161290321\n",
      "15\n",
      "4176 0.8808080808080808 0.9117647058823529 0.7591836734693876 0.6503496503496503 0.7591836734693876\n",
      "4192 0.8808080808080808 0.9038461538461539 0.7611336032388664 0.6573426573426573 0.7611336032388664\n",
      "4177 0.8808080808080808 0.9 0.7620967741935485 0.6608391608391608 0.7620967741935485\n",
      "4177 0.8808080808080808 0.9 0.7620967741935485 0.6608391608391608 0.7620967741935485\n",
      "4170 0.8848484848484849 0.9215686274509803 0.7673469387755102 0.6573426573426573 0.7673469387755102\n",
      "20\n",
      "4176 0.8838383838383839 0.9130434782608695 0.766734279918864 0.6608391608391608 0.766734279918864\n",
      "4175 0.8838383838383839 0.9052132701421801 0.7686116700201207 0.6678321678321678 0.7686116700201207\n",
      "4175 0.8838383838383839 0.9052132701421801 0.7686116700201207 0.6678321678321678 0.7686116700201207\n",
      "4188 0.8858585858585859 0.9178743961352657 0.77079107505071 0.6643356643356644 0.77079107505071\n",
      "4171 0.8858585858585859 0.9138755980861244 0.7717171717171717 0.6678321678321678 0.7717171717171717\n",
      "25\n",
      "4170 0.8868686868686869 0.910377358490566 0.7751004016064258 0.6748251748251748 0.7751004016064258\n",
      "4170 0.8868686868686869 0.910377358490566 0.7751004016064258 0.6748251748251748 0.7751004016064258\n",
      "4177 0.8858585858585859 0.909952606635071 0.7726358148893361 0.6713286713286714 0.7726358148893361\n",
      "4186 0.8868686868686869 0.9182692307692307 0.7732793522267207 0.6678321678321678 0.7732793522267207\n",
      "4175 0.8868686868686869 0.9182692307692307 0.7732793522267207 0.6678321678321678 0.7732793522267207\n",
      "30\n",
      "4170 0.8868686868686869 0.9182692307692307 0.7732793522267207 0.6678321678321678 0.7732793522267207\n",
      "4170 0.8868686868686869 0.9182692307692307 0.7732793522267207 0.6678321678321678 0.7732793522267207\n",
      "4175 0.8878787878787879 0.9227053140096618 0.7748478701825559 0.6678321678321678 0.7748478701825559\n",
      "4175 0.8878787878787879 0.9227053140096618 0.7748478701825559 0.6678321678321678 0.7748478701825559\n",
      "4177 0.8878787878787879 0.9227053140096618 0.7748478701825559 0.6678321678321678 0.7748478701825559\n",
      "35\n",
      "4175 0.8878787878787879 0.9227053140096618 0.7748478701825559 0.6678321678321678 0.7748478701825559\n",
      "4175 0.8888888888888888 0.9271844660194175 0.7764227642276423 0.6678321678321678 0.7764227642276423\n",
      "4175 0.8888888888888888 0.9271844660194175 0.7764227642276423 0.6678321678321678 0.7764227642276423\n",
      "4171 0.8888888888888888 0.9271844660194175 0.7764227642276423 0.6678321678321678 0.7764227642276423\n",
      "4175 0.8888888888888888 0.9271844660194175 0.7764227642276423 0.6678321678321678 0.7764227642276423\n",
      "40\n",
      "4171 0.8888888888888888 0.9271844660194175 0.7764227642276423 0.6678321678321678 0.7764227642276423\n",
      "4174 0.8888888888888888 0.9271844660194175 0.7764227642276423 0.6678321678321678 0.7764227642276423\n",
      "4174 0.8888888888888888 0.9271844660194175 0.7764227642276423 0.6678321678321678 0.7764227642276423\n",
      "4181 0.8888888888888888 0.9271844660194175 0.7764227642276423 0.6678321678321678 0.7764227642276423\n",
      "4182 0.8888888888888888 0.9271844660194175 0.7764227642276423 0.6678321678321678 0.7764227642276423\n",
      "45\n",
      "4187 0.8888888888888888 0.9271844660194175 0.7764227642276423 0.6678321678321678 0.7764227642276423\n",
      "4168 0.8888888888888888 0.9271844660194175 0.7764227642276423 0.6678321678321678 0.7764227642276423\n",
      "4172 0.8888888888888888 0.9271844660194175 0.7764227642276423 0.6678321678321678 0.7764227642276423\n",
      "4179 0.8888888888888888 0.9271844660194175 0.7764227642276423 0.6678321678321678 0.7764227642276423\n",
      "4177 0.8888888888888888 0.9271844660194175 0.7764227642276423 0.6678321678321678 0.7764227642276423\n",
      "50\n",
      "4175 0.8888888888888888 0.9271844660194175 0.7764227642276423 0.6678321678321678 0.7764227642276423\n",
      "4168 0.8888888888888888 0.9271844660194175 0.7764227642276423 0.6678321678321678 0.7764227642276423\n",
      "4169 0.8888888888888888 0.9271844660194175 0.7764227642276423 0.6678321678321678 0.7764227642276423\n",
      "4173 0.8888888888888888 0.9271844660194175 0.7764227642276423 0.6678321678321678 0.7764227642276423\n",
      "4178 0.8888888888888888 0.9271844660194175 0.7764227642276423 0.6678321678321678 0.7764227642276423\n",
      "55\n",
      "4179 0.8888888888888888 0.9271844660194175 0.7764227642276423 0.6678321678321678 0.7764227642276423\n",
      "4166 0.8888888888888888 0.9271844660194175 0.7764227642276423 0.6678321678321678 0.7764227642276423\n",
      "4180 0.8888888888888888 0.9271844660194175 0.7764227642276423 0.6678321678321678 0.7764227642276423\n",
      "4168 0.8888888888888888 0.9271844660194175 0.7764227642276423 0.6678321678321678 0.7764227642276423\n",
      "4178 0.8888888888888888 0.9271844660194175 0.7764227642276423 0.6678321678321678 0.7764227642276423\n",
      "60\n",
      "4174 0.8888888888888888 0.9271844660194175 0.7764227642276423 0.6678321678321678 0.7764227642276423\n",
      "4173 0.8888888888888888 0.9271844660194175 0.7764227642276423 0.6678321678321678 0.7764227642276423\n",
      "4169 0.8888888888888888 0.9271844660194175 0.7764227642276423 0.6678321678321678 0.7764227642276423\n",
      "4169 0.8888888888888888 0.9271844660194175 0.7764227642276423 0.6678321678321678 0.7764227642276423\n",
      "4180 0.8888888888888888 0.9271844660194175 0.7764227642276423 0.6678321678321678 0.7764227642276423\n",
      "65\n",
      "4173 0.8888888888888888 0.9271844660194175 0.7764227642276423 0.6678321678321678 0.7764227642276423\n",
      "4184 0.8888888888888888 0.9271844660194175 0.7764227642276423 0.6678321678321678 0.7764227642276423\n",
      "4177 0.8888888888888888 0.9271844660194175 0.7764227642276423 0.6678321678321678 0.7764227642276423\n",
      "4180 0.8888888888888888 0.9271844660194175 0.7764227642276423 0.6678321678321678 0.7764227642276423\n",
      "4176 0.8888888888888888 0.9271844660194175 0.7764227642276423 0.6678321678321678 0.7764227642276423\n",
      "70\n",
      "4174 0.8888888888888888 0.9271844660194175 0.7764227642276423 0.6678321678321678 0.7764227642276423\n",
      "4184 0.8888888888888888 0.9271844660194175 0.7764227642276423 0.6678321678321678 0.7764227642276423\n",
      "4180 0.8888888888888888 0.9271844660194175 0.7764227642276423 0.6678321678321678 0.7764227642276423\n",
      "4177 0.8888888888888888 0.9271844660194175 0.7764227642276423 0.6678321678321678 0.7764227642276423\n",
      "4180 0.8888888888888888 0.9271844660194175 0.7764227642276423 0.6678321678321678 0.7764227642276423\n",
      "75\n",
      "4177 0.8888888888888888 0.9271844660194175 0.7764227642276423 0.6678321678321678 0.7764227642276423\n",
      "4178 0.8888888888888888 0.9271844660194175 0.7764227642276423 0.6678321678321678 0.7764227642276423\n",
      "4172 0.8888888888888888 0.9271844660194175 0.7764227642276423 0.6678321678321678 0.7764227642276423\n",
      "4183 0.8888888888888888 0.9271844660194175 0.7764227642276423 0.6678321678321678 0.7764227642276423\n",
      "4180 0.8888888888888888 0.9271844660194175 0.7764227642276423 0.6678321678321678 0.7764227642276423\n",
      "80\n",
      "4177 0.8888888888888888 0.9271844660194175 0.7764227642276423 0.6678321678321678 0.7764227642276423\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4173 0.8888888888888888 0.9271844660194175 0.7764227642276423 0.6678321678321678 0.7764227642276423\n",
      "4177 0.8888888888888888 0.9271844660194175 0.7764227642276423 0.6678321678321678 0.7764227642276423\n",
      "4182 0.8888888888888888 0.9271844660194175 0.7764227642276423 0.6678321678321678 0.7764227642276423\n",
      "4184 0.8888888888888888 0.9271844660194175 0.7764227642276423 0.6678321678321678 0.7764227642276423\n",
      "85\n",
      "4178 0.8888888888888888 0.9271844660194175 0.7764227642276423 0.6678321678321678 0.7764227642276423\n",
      "4180 0.8888888888888888 0.9271844660194175 0.7764227642276423 0.6678321678321678 0.7764227642276423\n",
      "4180 0.8888888888888888 0.9271844660194175 0.7764227642276423 0.6678321678321678 0.7764227642276423\n",
      "4179 0.8888888888888888 0.9271844660194175 0.7764227642276423 0.6678321678321678 0.7764227642276423\n",
      "4180 0.8888888888888888 0.9271844660194175 0.7764227642276423 0.6678321678321678 0.7764227642276423\n",
      "90\n",
      "4182 0.8888888888888888 0.9271844660194175 0.7764227642276423 0.6678321678321678 0.7764227642276423\n",
      "4175 0.8888888888888888 0.9271844660194175 0.7764227642276423 0.6678321678321678 0.7764227642276423\n",
      "4171 0.8888888888888888 0.9271844660194175 0.7764227642276423 0.6678321678321678 0.7764227642276423\n",
      "4181 0.8888888888888888 0.9271844660194175 0.7764227642276423 0.6678321678321678 0.7764227642276423\n",
      "4182 0.8888888888888888 0.9271844660194175 0.7764227642276423 0.6678321678321678 0.7764227642276423\n",
      "95\n",
      "4176 0.8888888888888888 0.9271844660194175 0.7764227642276423 0.6678321678321678 0.7764227642276423\n",
      "4174 0.8888888888888888 0.9271844660194175 0.7764227642276423 0.6678321678321678 0.7764227642276423\n",
      "4175 0.8888888888888888 0.9271844660194175 0.7764227642276423 0.6678321678321678 0.7764227642276423\n",
      "4176 0.8888888888888888 0.9271844660194175 0.7764227642276423 0.6678321678321678 0.7764227642276423\n",
      "4182 0.8888888888888888 0.9271844660194175 0.7764227642276423 0.6678321678321678 0.7764227642276423\n",
      "4182 0.7764227642276423\n"
     ]
    }
   ],
   "source": [
    "fittest_individual = ga.run_algorithm()\n",
    "# takes ~2s per generation (for population of size 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'10000100010101110101010010000101111000101011000000001001110111110010101101101000000111001011001111110100000110001101101011000000011110110110110101011110000000100000101100000000111100110010011000010011101000110010001101111011110011111100000111001010101011001111110001010011011100110001010110110001001000011000101010110000000101010010001101010101001110011011101110011101100101100110000011111110001100111101111000110010011011001111100001110110011110001100010000000010011101010110111110101100110011111001011110100010100111000001111010011101111010101000000110110101100001100001001010100010000011100001110010111001001011111111000101100010001011100010101000010000111001101000101001001010100111111000100111010101110011001011010000011100010111000011101110100000110111100110011010100011000010101110111111011101011100101100111000010111010001110100011111001100010111001101010111000010011011010010000011000101111010010001111010011100011001001111100101101011111010100101110111010101000001000100110010001100100001001110011101100111001010001010010110001111001011001100011010010111000000110101001010100101100111001001011111001100000111111101000111100101110110100000000001000001010011110100101111111011101001110101100100001100111100100110100001110100001101111101000101010110111100001101100101101010111111010001111000111100110101100001010010101101001000111110110101101001101000100001100001110000001110111001000110101010000100110101001000000011001101010101000100011001000001111100111010000001111001011000000000110111101000111011011100000111011111000011000000010000000000010110011001010000001111110010010011101101000111010000101100010000010001010111110110001110010000000010010000101011111101011101101011101101100111111111001101100100100010011011000001011110101111110001100001110111010000000010111001011101111010111000010100111110110111010010110100111111010010010010110010001101001100101000111100000100111101011101000000001100111010010001000110111100110101100010011001101011101111011011100100101000110001100110011001000101100010000001010110000100001011011000001101100101110001010011111111111001000010100011110111100010100100000001100100000101011011110101100111110101101010001000010110110001010010100011100100001000100000111000011011101011000011000010110001110111111100001011000110111010010001110110100100110111101011101111110011100001110100101110010010011010100101111000100111111101011010000000011101001011011011000001110101101010001011110101100100001100111000111100010110101001100011010101011011011111010000100101101100011110111110101000101010000001011100001001000111111111000010101011111011011010011001010011101100010011100100111110100001000011101100101110001110001010110010011000000000001110101000000010010101011111110010101101000010010001101001011101001110100111110011110011011001000010100101011100100001101000110000001101101100101011011000100111110101101110011000011111111001011100011011001100101100101110001101011111110001000000100010001011101100110000010110101110001110110000101001101110110100011010100111011010001001110100000000011010100111010110001011101001011001011111110001110001100011000011001010101100000100101000010101101000101100111000001011010001110010000101010101001100110001111010100110101000100001110111111100001101110111001111110001000001001001110110110111111000000101111100110001110101011001001110010110011000100001101010010001011100110001110010000111011001000100110110010011100111001101001001100111000111000100110100001000101010111100011110111000010100100101011101110111100110001011010000100001000110001100111111011110001001101011110101000011111111101111010010011011101101000000101111101100101010000000110101010001011101011101110110110000000110011111010100010010100010101111101100011001111011110111111101010100100111101100000000111010101110111001001101011011000101001010010010110000110011000101100011011010010011111010010001100111100110100101111110000001011101000001111100100111010101111001001001000101000101111110100011110011000000011100110000100110110011000101000110010100001101011100001101000110010101010110011011110000010010011100000110011101101011100101001011011101011110101100100110000000011011101100000111010011100011110100001000100000111011000000001111000000110111000000101010100011001010001010100111100100000100010011000101111111011101101111000011110101000111101001111100100000110110101101000001100001101101010000010011110011100000010100011101011011000101001000011000110000001100101010101010111001110111101110010100001101100001100001111001100001111010011100110110110010001001010111001011011111100101000100111110110010110011001010101001010000001010101010111000011110000010111111000110000001101001101010110010111110111001110110111001010110111101110110010110001100101011110101001101100101111011111001000110110000001101111011100101000000010001110110000111100000111000001011101001110100111011011000100101000010100001010011101000101101000001100101011101100000110010100111110111111011101100010000110001111101001001011110100000100010110011100001100000011100001001110110111001110011010100101001011010101110110110101100111001000001011010110101000001110110001010011010001000111110110011010110100010110001011000110001110101100101001110001001010010101101101011101100100110111011111101011000111110000110100111111100110011000001111101100011110110011111110101101011011000000110101010101110100001111110110010011001011110001011100000111111111100001001011110011001010010111110101000001110111111011000100101110001001100101010000000100010100010010100001100001010100000000101010100000100101101000111001010011101001000100010001001011000101001010010010111011101011011110111011011010100001011100001000110001010011101111111000000101111101111011010000110011010001110100001101101010000001011000110110101101101100000000101110101010101110010011111101100110101100110110010000000111001011001011100111001010100110000011101010110001101100100001110010110000000111101101011110010010100000100101011011100011110111010000101010111101011010000001000110111110110100001011000100001100111000111000011011110001101100110100010001010110110111001100011100110100011111011011110111101010101000100001110110000000001001001100011000001000101101000100001111101010001100000001111111100011010111111001010011100000100100000001010110001000011110110010000001101110110010011101011000111010001011100101110011100101001011010110101011100110101000101110001010100100110100111100110001111000110100110101000110100001100000001000101110110010000011100010111110001111011000000111010011011101010110101011010101110111001000000011001000111111010000010010100101100100110110110100000111011110100001111010000100110111101011111011101000100111111100000101010111101110000110010101101110010011000101001111100001011111011110111111010011000111100111100011101101001000111111001010000111100100011110100011010100010101101010001010100011010000011110010010000000111111010110110100110010111101110111101011011010110110100101000100101000011100001010100110010100001001010110111010010101010000010110011100001000100101111100001000100011000111011011110101001111101100111111100010100001100111010111111110000010000000001011100001011001010111001001110110010100111101011100001000000000101010110110111111100101000101010000111101101010001000001101110100001010101001110100011011110101000011001010111000000100000010100110011010100111111000101010000011000010001101001110110101000001011101111001100111000010110010010001100011011100000111000110100010100010100001110100010111010110000110111000111001000001010100110101010011100011111001001001001111111010100110101010000110111111110100110001000111010101111101011110011011001100110011110110011011001001000110001101001100101001110111111110000111111000011010101001010011111110000111001100110011010100011110011111100100110000100100100011100011000010010000011010010111110010111100100000101111011111101100000000110110110100010111010001011010000111100110111110101000100010100110001110011111011101001100111110110111111100000011001000101100001110111011111000011000001011111110010111111100111100000010001001110000110111101011010100000111100101110110011101000100100011100000110001000001110001011010101100010101110000011001011110111000110010111000100100010100110001100010111001010110000000000111111111000011000100000111001010010010101100000000010010100010110101111010110000010100100110110111001001101110110001100111001101011001000111000110001101111001000101011101110100010101011101000111111110111101000011000101010010111011100010101000011000000010000001001111100111001110101111010001000010000000100001011010000010111011100111100010100100111110001000100010010001100'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fittest_individual # List[Boolean]\n",
    "''.join([str(int(x)) for x in fittest_individual])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8888888888888888,\n",
       " 0.9271844660194175,\n",
       " 0.7764227642276423,\n",
       " 0.6678321678321678)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# devset\n",
    "acc, pre, fscore, recall = svm_calc_fitness(fittest_individual)\n",
    "acc, pre, fscore, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8465608465608465,\n",
       " 0.8548387096774194,\n",
       " 0.7090301003344482,\n",
       " 0.6057142857142858)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testset\n",
    "acc, pre, fscore, recall = svm_calc_fitness(fittest_individual, mode='test')\n",
    "acc, pre, fscore, recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code Flow\n",
    "- Feature extraction from the corpus (uni, bi, tri, tf-idf, lda, pos, nrc)\n",
    "- GA (meta-heuristic) for feature selection\n",
    "  - population of individuals, where each individual corresponds to a bitmask of features to select\n",
    "  - individuals evolve over the generations by cross-over and mutation\n",
    "  - fitness of individuals is evaluated using F1 score (this score is calculated on devset by fitting the model with a small amount of trainset for guiding GA)\n",
    "  - after GA finishes, we end up we the fittest individual ie the optimal feature set (denoted by a bitmask) (giving a good reduction of 50%)\n",
    "- Finally we train our model on the complete training set based on the selected features and evaluate it on testset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
