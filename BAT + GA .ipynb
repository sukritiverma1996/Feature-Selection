{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "from random import randint\n",
    "import random\n",
    "import math\n",
    "from collections import defaultdict\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import svm\n",
    "import operator\n",
    "import sklearn.metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "from sklearn.naive_bayes import GaussianNB as GNB\n",
    "from pandas import DataFrame, read_csv\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from deap import creator, base, tools, algorithms\n",
    "from nltk.tokenize import TweetTokenizer # a tweet tokenizer from nltk.\n",
    "tokenizer = TweetTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.test.utils import common_texts, get_tmpfile\n",
    "from gensim.models import Word2Vec\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.KeyedVectors.load_word2vec_format('/Users/sukrverm/Documents/GoogleNews-vectors-negative300.bin', binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1 = '/Users/sukrverm/Documents/NLP-Review/safecity/binary_classification/ogling_data/train.csv'\n",
    "df = pd.read_csv(file1)\n",
    "print(df.head())\n",
    "\n",
    "corpus = list(df[\"Description\"])\n",
    "target = list(df[\"Category\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infinity = float(\"inf\") #sentinel maximum value\n",
    "m = 70 #no of bats (50-70)\n",
    "T = 100 # no of iterations(100)\n",
    "\n",
    "bat_pos = defaultdict(list)\n",
    "bat_vel = defaultdict(list)\n",
    "bat_loudness = []\n",
    "bat_rate = []\n",
    "bat_fitness = []\n",
    "bat_frequency = []\n",
    "\n",
    "global_bat_pos = []\n",
    "init_rate_vector = []\n",
    "feature_vector = []\n",
    "\n",
    "#hyper parameters\n",
    "alpha = 0.9\n",
    "gamma = 0.9\n",
    "epsilon = random.uniform(-1,1)\n",
    "fmin=0\n",
    "fmax =1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#do once\n",
    "#nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 3), stop_words=stop_words)\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "tfidf = dict(zip(vectorizer.get_feature_names(), vectorizer.idf_))\n",
    "print(X.shape)\n",
    "print(vectorizer.get_feature_names()[0:50])\n",
    "print(len(vectorizer.get_feature_names()))\n",
    "\n",
    "X_train = X\n",
    "Y_train = target\n",
    "\n",
    "file2 = '/Users/sukrverm/Documents/NLP-Review/safecity/binary_classification/ogling_data/dev.csv'\n",
    "df_dev = pd.read_csv(file2)\n",
    "print(df_dev.head())\n",
    "corpus_dev = list(df_dev[\"Description\"])\n",
    "target_dev = list(df_dev[\"Category\"])\n",
    "X_dev = vectorizer.transform(corpus_dev)\n",
    "print(X_dev.shape)\n",
    "Y_dev = target_dev\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildWordVector(tweet, size):\n",
    "    vec = np.zeros(size).reshape((1, size))\n",
    "    tokens = tokenize(tweet)\n",
    "    print(tokens)\n",
    "    count = 0.\n",
    "    for word in tokens:\n",
    "        try:\n",
    "            vec += model.word_vec(word).reshape((1, size)) * tfidf[word]\n",
    "            count += 1.\n",
    "        except KeyError: # handling the case where the token is not\n",
    "                         # in the corpus. useful for testing.\n",
    "            continue\n",
    "    if count != 0:\n",
    "        vec /= count\n",
    "    return vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(tweet):\n",
    "    try:\n",
    "        tweet = unicode(tweet.decode('utf-8').lower())\n",
    "        tokens = tokenizer.tokenize(tweet)\n",
    "        tokens = filter(lambda t: not t.startswith('@'), tokens)\n",
    "        tokens = filter(lambda t: not t.startswith('#'), tokens)\n",
    "        tokens = filter(lambda t: not t.startswith('http'), tokens)\n",
    "        return tokens\n",
    "    except:\n",
    "        print('NC')\n",
    "        return 'NC'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_train_vecs_w2v = np.concatenate([buildWordVector(tweet, 300) for tweet in corpus])\n",
    "corpus_dev_vecs_w2v = np.concatenate([buildWordVector(tweet, 300) for tweet in corpus_dev])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(corpus_dev_vecs_w2v.shape)\n",
    "print(corpus_dev_vecs_w2v[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#auxillary  functions\n",
    "def extract_subset(z,cols):\n",
    "    return z[:,cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_calc_fitness(x):\n",
    "    for i in range(0,len(x)):\n",
    "        x[i] = x[i] > 0.5\n",
    "    cols = []\n",
    "    #for j in range(0, X_train.shape[1]):\n",
    "    for j in range(0, corpus_train_vecs_w2v.shape[1]):\n",
    "        if x[j] == 1:\n",
    "            cols.append(j)\n",
    "    #z1_prime = extract_subset(X_train, cols)\n",
    "    #z2_prime = extract_subset(X_dev, cols)\n",
    "    z1_prime = extract_subset(corpus_train_vecs_w2v, cols)\n",
    "    z2_prime = extract_subset(corpus_dev_vecs_w2v, cols)\n",
    "    clf = svm.LinearSVC(C=1.0)\n",
    "    clf.fit(z1_prime, Y_train)\n",
    "    y_pred = clf.predict(z2_prime)\n",
    "    acc = sklearn.metrics.accuracy_score(Y_dev,y_pred)\n",
    "    pre = sklearn.metrics.precision_score(Y_dev,y_pred)\n",
    "    fscore = sklearn.metrics.f1_score(Y_dev,y_pred)\n",
    "    recall = sklearn.metrics.recall_score(Y_dev,y_pred)\n",
    "    return (acc),pre,fscore,recall\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf_calc_fitness(x):\n",
    "    for i in range(0,len(x)):\n",
    "        x[i] = x[i] > 0.5\n",
    "    cols = []\n",
    "    for j in range(0, n):\n",
    "        if x[j] == 1:\n",
    "            cols.append(j)\n",
    "    z1_prime = extract_subset(z1, cols)\n",
    "    z2_prime = extract_subset(z2, cols)\n",
    "    clf = RandomForestClassifier(n_jobs=2,random_state=0)\n",
    "    clf.fit(z1_prime, Y_train)\n",
    "    y_pred = clf.predict(z2_prime)\n",
    "    acc = sklearn.metrics.accuracy_score(Y_test,y_pred)\n",
    "    pre = sklearn.metrics.precision_score(Y_test,y_pred)\n",
    "    fscore = sklearn.metrics.f1_score(Y_test,y_pred)\n",
    "    recall = sklearn.metrics.recall_score(Y_test,y_pred)\n",
    "    return (acc),pre,fscore,recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_calc_fitness(x):\n",
    "    for i in range(0,len(x)):\n",
    "        x[i] = x[i] > 0.5\n",
    "    cols = []\n",
    "    for j in range(0, n):\n",
    "        if x[j] == 1:\n",
    "            cols.append(j)\n",
    "    z1_prime = extract_subset(z1, cols)\n",
    "    z2_prime = extract_subset(z2, cols)\n",
    "    clf = KNN(3,weights='uniform')\n",
    "    clf.fit(z1_prime, Y_train)\n",
    "    y_pred = clf.predict(z2_prime)\n",
    "    acc = sklearn.metrics.accuracy_score(Y_test,y_pred)\n",
    "    pre = sklearn.metrics.precision_score(Y_test,y_pred)\n",
    "    fscore = sklearn.metrics.f1_score(Y_test,y_pred)\n",
    "    recall = sklearn.metrics.recall_score(Y_test,y_pred)\n",
    "    return (acc),pre,fscore,recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nb_calc_fitness(x):\n",
    "    for i in range(0,len(x)):\n",
    "        x[i] = x[i] > 0.5\n",
    "    cols = []\n",
    "    for j in range(0, n):\n",
    "        if x[j] == 1:\n",
    "            cols.append(j)\n",
    "    z1_prime = extract_subset(z1, cols)\n",
    "    z2_prime = extract_subset(z2, cols)\n",
    "    clf = GNB()\n",
    "    clf.fit(z1_prime, Y_train)\n",
    "    y_pred = clf.predict(z2_prime)\n",
    "    acc = sklearn.metrics.accuracy_score(Y_test,y_pred)\n",
    "    pre = sklearn.metrics.precision_score(Y_test,y_pred)\n",
    "    fscore = sklearn.metrics.f1_score(Y_test,y_pred)\n",
    "    recall = sklearn.metrics.recall_score(Y_test,y_pred)\n",
    "    return (acc),pre,fscore,recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialise(m,n):\n",
    "    for i in range(0,m):\n",
    "        for j in range(0,n):\n",
    "            x = randint(0,1)\n",
    "            bat_pos[i].append(x)\n",
    "            bat_vel[i].append(0)\n",
    "\n",
    "        init_rate_vector.append(random.uniform(0, 1))\n",
    "\n",
    "        bat_frequency.append(init_rate_vector[i])\n",
    "        bat_loudness.append(random.uniform(1,2))\n",
    "        bat_rate.append(init_rate_vector[i])\n",
    "        bat_fitness.append(-infinity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def core():\n",
    "    initialise(m,n)\n",
    "    global_fit = -infinity\n",
    "    for t in range (0,T):\n",
    "        print(\"T:\" , t)\n",
    "        for i in range(0,m):\n",
    "            accuracy,pre,fscore,recall = svm_calc_fitness(bat_pos[i])\n",
    "            '''\n",
    "            with open(\"dumpPerformanceBat_svm_kpi.txt\", \"a\") as text_file:\n",
    "                text_file.write(\"{} {} {} {} {}\".format(accuracy,pre,fscore,recall,global_fit) + \"\\n\")\n",
    "            with open(\"dumpPerformanceBat_svm.txt\", \"a\") as text_file:\n",
    "                text_file.write(\"{} {} {} {}\".format(t,accuracy,bat_pos[i].count(1),global_fit)+\"\\n\")\n",
    "            #print(\"t={} accuracy={} #features={} global_fit={}\".format(t,accuracy,bat_pos[i].count(1),global_fit))\n",
    "            '''\n",
    "            acc = accuracy\n",
    "\n",
    "            rand = randint(0,1)\n",
    "            if rand < bat_loudness[i] and acc > bat_fitness[i]:\n",
    "                bat_fitness[i]=acc\n",
    "                bat_loudness[i]= alpha * bat_loudness[i]\n",
    "                bat_rate[i]= init_rate_vector[i] * (1 - math.exp(-(gamma * t)))\n",
    "\n",
    "        maxindex,maxfit = max(enumerate(bat_fitness), key=operator.itemgetter(1))\n",
    "\n",
    "        if maxfit>global_fit :\n",
    "            global_fit = maxfit\n",
    "            global_bat_pos = bat_pos[maxindex]\n",
    "\n",
    "        for i in range(0,m): # for each bat\n",
    "            beta = random.uniform(0,1)\n",
    "            rand = random.uniform(0,1)\n",
    "            AvgA = sum(bat_loudness)/len(bat_loudness)\n",
    "\n",
    "            if rand > bat_rate[i] :\n",
    "                for j in range(0,n):\n",
    "                    bat_pos[i][j] = bat_pos[i][j] + ( epsilon * AvgA )\n",
    "                    sigma = randint(0,1)\n",
    "                    if sigma < (1/(1+math.exp(-bat_pos[i][j]))) :\n",
    "                        bat_pos[i][j]=1\n",
    "                    else :\n",
    "                        bat_pos[i][j]= 0\n",
    "\n",
    "            rand = random.uniform(0,1)\n",
    "            if rand < bat_loudness[i] and bat_fitness[i] < global_fit :\n",
    "                for j in range (0,n):\n",
    "                    bat_frequency[i] = fmin + (fmax-fmin)* beta\n",
    "                    bat_vel[i][j] = bat_vel[i][j] + (global_bat_pos[j]-bat_pos[i][j]) * bat_frequency[i]\n",
    "                    bat_pos[i][j] = bat_pos[i][j] + bat_vel[i][j]\n",
    "                    sigma = random.uniform(0,1)\n",
    "                    if sigma < (1 / (1 + math.exp(-bat_pos[i][j]))) :\n",
    "                        bat_pos[i][j]=1\n",
    "                    else :\n",
    "                        bat_pos[i][j]=0\n",
    "        with open(\"dumpPerformanceBat_rf.txt\", \"a\") as text_file:\n",
    "            text_file.write(\"{} {} {} \".format(t,global_bat_pos.count(1),global_fit)+\"\\n\")\n",
    "        \n",
    "\n",
    "\n",
    "    feature_vector = global_bat_pos\n",
    "    return feature_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BAT_algo():\n",
    "    feature_vector = core()\n",
    "    return feature_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = BAT_algo()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneticAlgorithm():\n",
    "    \n",
    "    def __init__(self, X_train, X_test, Y_train, Y_test, number_bits_to_mutate = 25.0):\n",
    "        \n",
    "        \n",
    "        self.toolbox = base.Toolbox()\n",
    "        self.ind_mut_pb = float(number_bits_to_mutate / X_train.shape[1])\n",
    "        self.NGEN = 100\n",
    "        self.MUTPB = 0.2\n",
    "        self.CXPB = 0.5\n",
    "        self.POPULATION_SIZE = 70\n",
    "        self.NUMBER_TO_SELECT_FROM_POP = 35\n",
    "        self.init_pop = list()\n",
    "        self.X_tr = X_train\n",
    "        self.X_te = X_test\n",
    "        self.Y_train = Y_train\n",
    "        self.Y_test = Y_test\n",
    "        \n",
    "    \n",
    "    def initialise_toolbox(self):\n",
    "        print('now initializing toolbox GA1')\n",
    "        # I want to maximize session overlap as well as length\n",
    "        creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
    "        # representing individual as a list\n",
    "        creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
    "        # individual will be a list of 0/1\n",
    "        self.toolbox.register(\"attr_bool\", random.randint, 0, 1)\n",
    "        IND_DIMENSIONALITY = self.X_tr.shape[1]\n",
    "        # create template for individual\n",
    "        self.toolbox.register(\"individual\", tools.initRepeat, creator.Individual, self.toolbox.attr_bool, n=IND_DIMENSIONALITY)\n",
    "        #self.toolbox.register(\"individual\", tools.initIterate, creator.Individual, self.get_ind)\n",
    "        # create template for population\n",
    "        self.toolbox.register(\"population\", tools.initRepeat, list, self.toolbox.individual)\n",
    "        print('toolbox initialised')\n",
    "    \n",
    "    \n",
    "    def initialise_fitness_function(self):\n",
    "        print('building and registering the fitness function')\n",
    "        \n",
    "        def fitness(individual):\n",
    "            \n",
    "            \n",
    "            accuracy,pre,fscore,recall = svm_calc_fitness(individual)\n",
    "            return fscore,\n",
    "            \n",
    "        \n",
    "        self.toolbox.register(\"evaluate\", lambda individual: fitness(individual))\n",
    "        self.toolbox.register(\"mate\", tools.cxOnePoint)\n",
    "        self.toolbox.register(\"mutate\", tools.mutFlipBit, indpb=self.MUTPB)\n",
    "        self.toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
    "        \n",
    "        print('fitness function ready')\n",
    "    \n",
    "    def run_algorithm(self):\n",
    "        \n",
    "        self.initialise_toolbox()\n",
    "        self.initialise_fitness_function()\n",
    "        \n",
    "        print('mutation probability was calculated at %f' % self.ind_mut_pb)\n",
    "        print('running the algorithm')\n",
    "        toolbox = self.toolbox\n",
    "        # create a population of size n\n",
    "        pop = toolbox.population(n=self.POPULATION_SIZE)\n",
    "        \n",
    "        \n",
    "        for gen in range(self.NGEN):\n",
    "            # Select the next generation individuals\n",
    "            if gen%5 == 0:\n",
    "                print(gen)\n",
    "            offspring = toolbox.select(pop, len(pop))\n",
    "            \n",
    "            for ind in offspring:\n",
    "                if ind.fitness.valid:\n",
    "                    pass\n",
    "            # Clone the selected individuals\n",
    "            offspring = map(toolbox.clone, offspring)\n",
    "\n",
    "            # Apply crossover on the offspring\n",
    "            for child1, child2 in zip(offspring[::2], offspring[1::2]):\n",
    "                if random.random() < self.CXPB:\n",
    "                    #toolbox.mate(child1, child2)\n",
    "                    tools.cxUniform(child1, child2, 0.5)\n",
    "                    del child1.fitness.values\n",
    "                    del child2.fitness.values\n",
    "\n",
    "            # Apply mutation on the offspring\n",
    "            for mutant in offspring:\n",
    "                if random.random() < self.MUTPB:\n",
    "                    # print('now doing mutation')\n",
    "                    toolbox.mutate(mutant)\n",
    "                    del mutant.fitness.values\n",
    "\n",
    "            # Evaluate the individuals with an invalid fitness\n",
    "            invalid_ind = [ind for ind in offspring if not ind.fitness.valid]\n",
    "            fitnesses = toolbox.map(toolbox.evaluate, invalid_ind)\n",
    "            \n",
    "            added = 0\n",
    "            for ind, fit in zip(invalid_ind, fitnesses):\n",
    "                ind.fitness.values = fit\n",
    "                \n",
    "\n",
    "            # The population is entirely replaced by the offspring\n",
    "            pop[:] = offspring\n",
    "            top = tools.selBest(pop, k=self.NUMBER_TO_SELECT_FROM_POP)\n",
    "            \n",
    "            # Dump best individual to file\n",
    "            fittest = tools.selBest(pop, k=1)[0]\n",
    "            count = 0\n",
    "            for i in range(0, len(fittest)):\n",
    "                if fittest[i] == 1:\n",
    "                    count = count + 1 \n",
    "            with open(\"GA_performance.txt\", \"a\") as text_file:\n",
    "                accuracy,prec,fscore,recall = svm_calc_fitness(fittest)\n",
    "                text_file.write(\"{} {}\".format(count,fittest.fitness.values[0])+\"\\n\")\n",
    "                print(count,accuracy,prec,fscore,recall,fittest.fitness.values[0])\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        max_fitness = float(\"-inf\")\n",
    "        \n",
    "        for individual in tools.selBest(pop, k=1):\n",
    "            if individual.fitness.valid:\n",
    "                if individual.fitness.values[0] > max_fitness:\n",
    "                    max_fitness = individual.fitness.values[0]\n",
    "                    fittest_individual = individual\n",
    "                    \n",
    "        count = 0\n",
    "        for i in range(0, len(fittest_individual)):\n",
    "            if fittest_individual[i] == 1:\n",
    "                count = count + 1        \n",
    "        \n",
    "        print(count, max_fitness)\n",
    "        return fittest_individual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ga = GeneticAlgorithm(corpus_train_vecs_w2v, corpus_dev_vecs_w2v, Y_train, Y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fittest_individual = ga.run_algorithm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file3 = '/Users/sukrverm/Documents/NLP-Review/safecity/binary_classification/ogling_data/test.csv'\n",
    "df_test = pd.read_csv(file3)\n",
    "print(df_test.head())\n",
    "corpus_test = list(df_test[\"Description\"])\n",
    "target_test = list(df_test[\"Category\"])\n",
    "X_test = vectorizer.transform(corpus_test)\n",
    "print(X_test.shape)\n",
    "print(vectorizer.get_feature_names()[0:50])\n",
    "print(len(vectorizer.get_feature_names()))\n",
    "Y_test = target_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_test_vecs_w2v = np.concatenate([buildWordVector(tweet, 300) for tweet in corpus_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_calc_final_metrics(x):\n",
    "    for i in range(0,len(x)):\n",
    "        x[i] = x[i] > 0.5\n",
    "    cols = []\n",
    "    print(X_test.shape[0])\n",
    "    #for j in range(0, X_train.shape[1]):\n",
    "    for j in range(0, corpus_train_vecs_w2v.shape[1]):\n",
    "        if x[j] == 1:\n",
    "            cols.append(j)\n",
    "    #z1_prime = extract_subset(X_train, cols)\n",
    "    #z2_prime = extract_subset(X_test, cols)\n",
    "    z1_prime = extract_subset(corpus_train_vecs_w2v, cols)\n",
    "    z2_prime = extract_subset(corpus_test_vecs_w2v, cols)\n",
    "    clf = svm.LinearSVC(C=1.0)\n",
    "    clf.fit(z1_prime, Y_train)\n",
    "    y_pred = clf.predict(z2_prime)\n",
    "    acc = sklearn.metrics.accuracy_score(Y_test,y_pred)\n",
    "    pre = sklearn.metrics.precision_score(Y_test,y_pred)\n",
    "    fscore = sklearn.metrics.f1_score(Y_test,y_pred)\n",
    "    recall = sklearn.metrics.recall_score(Y_test,y_pred)\n",
    "    return (acc),pre,fscore,recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy,prec,fscore,recall = svm_calc_final_metrics(fittest_individual)\n",
    "print(accuracy,prec,fscore,recall,fittest_individual.fitness.values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
