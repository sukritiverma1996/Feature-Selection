{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "from random import randint\n",
    "import random\n",
    "import math\n",
    "from collections import defaultdict\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import svm\n",
    "import operator\n",
    "import sklearn.metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "from sklearn.naive_bayes import GaussianNB as GNB\n",
    "from pandas import DataFrame, read_csv\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from deap import creator, base, tools, algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         Description  Category\n",
      "0  Was walking along crowded street, holding mums...         0\n",
      "1  This incident took place in the evening.I was ...         0\n",
      "2  I WAS WAITING FOR THE BUS. A MAN CAME ON A BIK...         1\n",
      "3                 Incident happened inside the train         0\n",
      "4  I witnessed an incident when a chain was bruta...         0\n"
     ]
    }
   ],
   "source": [
    "file1 = '../../data/safecity/binary/commenting/train.csv'\n",
    "df = pd.read_csv(file1)\n",
    "print(df.head())\n",
    "\n",
    "corpus = list(df[\"Description\"])\n",
    "target = list(df[\"Category\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# infinity = float(\"inf\") #sentinel maximum value\n",
    "# m = 70 #no of bats (50-70)\n",
    "# T = 100 # no of iterations(100)\n",
    "\n",
    "# bat_pos = defaultdict(list)\n",
    "# bat_vel = defaultdict(list)\n",
    "# bat_loudness = []\n",
    "# bat_rate = []\n",
    "# bat_fitness = []\n",
    "# bat_frequency = []\n",
    "\n",
    "# global_bat_pos = []\n",
    "# init_rate_vector = []\n",
    "# feature_vector = []\n",
    "\n",
    "# #hyperparameters\n",
    "# alpha = 0.9\n",
    "# gamma = 0.9\n",
    "# epsilon = random.uniform(-1,1)\n",
    "# fmin=0\n",
    "# fmax =1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7201, 8504)\n",
      "['00', '000', '00am', '00pm', '01', '03', '0300', '05', '06', '0740', '0800am', '0830', '08826862360', '0900', '0930', '0f', '10', '100', '1000', '1000am', '1011am', '1012', '1015', '1030', '1030am', '1030ish', '1030pm', '1050', '10pm', '10th', '11', '1115', '1130', '1139', '1150', '11am', '11h', '11th', '12', '1213', '1214', '1230', '1245', '12th', '12yearold', '12years', '12yrs', '13', '1314', '13th']\n",
      "8504\n",
      "                                         Description  Category\n",
      "0  Buses approaching to this place is highly unsafe.         1\n",
      "1                        a man was commenting at me.         1\n",
      "2                                    in a share auto         0\n",
      "3  I was coming out of a club at night with a few...         1\n",
      "4  One of my friends was molested in the crowd. T...         0\n",
      "(990, 8504)\n",
      "['00', '000', '00am', '00pm', '01', '03', '0300', '05', '06', '0740', '0800am', '0830', '08826862360', '0900', '0930', '0f', '10', '100', '1000', '1000am', '1011am', '1012', '1015', '1030', '1030am', '1030ish', '1030pm', '1050', '10pm', '10th', '11', '1115', '1130', '1139', '1150', '11am', '11h', '11th', '12', '1213', '1214', '1230', '1245', '12th', '12yearold', '12years', '12yrs', '13', '1314', '13th']\n",
      "8504\n",
      "                                         Description  Category\n",
      "0  During morning, a woman was walking by and thi...         1\n",
      "1  A man tried to brush his penis off of a woman'...         0\n",
      "2  This happened to a fellow passenger of mine tr...         0\n",
      "3                                             ogling         0\n",
      "4  When I was returning my home after finishing m...         0\n",
      "(1701, 8504)\n",
      "['00', '000', '00am', '00pm', '01', '03', '0300', '05', '06', '0740', '0800am', '0830', '08826862360', '0900', '0930', '0f', '10', '100', '1000', '1000am', '1011am', '1012', '1015', '1030', '1030am', '1030ish', '1030pm', '1050', '10pm', '10th', '11', '1115', '1130', '1139', '1150', '11am', '11h', '11th', '12', '1213', '1214', '1230', '1245', '12th', '12yearold', '12years', '12yrs', '13', '1314', '13th']\n",
      "8504\n"
     ]
    }
   ],
   "source": [
    "#do once\n",
    "# nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 1), stop_words=stop_words)\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "print(X.shape)\n",
    "print(vectorizer.get_feature_names()[0:50])\n",
    "print(len(vectorizer.get_feature_names()))\n",
    "\n",
    "X_train = X\n",
    "Y_train = target\n",
    "\n",
    "file2 = '../../data/safecity/binary/commenting/dev.csv'\n",
    "df_dev = pd.read_csv(file2)\n",
    "print(df_dev.head())\n",
    "corpus_dev = list(df_dev[\"Description\"])\n",
    "target_dev = list(df_dev[\"Category\"])\n",
    "X_dev = vectorizer.transform(corpus_dev)\n",
    "print(X_dev.shape)\n",
    "print(vectorizer.get_feature_names()[0:50])\n",
    "print(len(vectorizer.get_feature_names()))\n",
    "Y_dev = target_dev\n",
    "\n",
    "file3 = '../../data/safecity/binary/commenting/test.csv'\n",
    "df_test = pd.read_csv(file3)\n",
    "print(df_test.head())\n",
    "corpus_test = list(df_test[\"Description\"])\n",
    "target_test = list(df_test[\"Category\"])\n",
    "X_test = vectorizer.transform(corpus_test)\n",
    "print(X_test.shape)\n",
    "print(vectorizer.get_feature_names()[0:50])\n",
    "print(len(vectorizer.get_feature_names()))\n",
    "Y_test = target_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7201, 8504) (990, 8504)\n"
     ]
    }
   ],
   "source": [
    "z1, z2 = X_train, X_dev\n",
    "print(z1.shape, z2.shape)\n",
    "n = z1.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#auxillary  functions\n",
    "def extract_subset(z,cols):\n",
    "    return z[:,cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_calc_fitness(x, mode=None): # SVM classifier\n",
    "    if mode in (None, 'dev'): X_eval, Y_eval = X_dev, Y_dev\n",
    "    elif mode == 'test': X_eval, Y_eval = X_test, Y_test\n",
    "    elif mode == 'train': X_eval,  Y_eval = X_train, Y_train\n",
    "        \n",
    "    for i in range(0,len(x)):\n",
    "        x[i] = x[i] > 0.5\n",
    "    cols = []\n",
    "    for j in range(0, n):\n",
    "        if x[j] == 1:\n",
    "            cols.append(j)\n",
    "    z1_prime = extract_subset(X_train, cols)\n",
    "    z2_prime = extract_subset(X_eval, cols)\n",
    "    clf = svm.LinearSVC(C=1.0)\n",
    "    clf.fit(z1_prime, Y_train)\n",
    "    y_pred = clf.predict(z2_prime)\n",
    "    \n",
    "    acc = sklearn.metrics.accuracy_score(Y_eval,y_pred)\n",
    "    pre = sklearn.metrics.precision_score(Y_eval,y_pred)\n",
    "    fscore = sklearn.metrics.f1_score(Y_eval,y_pred)\n",
    "    recall = sklearn.metrics.recall_score(Y_eval,y_pred)\n",
    "    return acc,pre,fscore,recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf_calc_fitness(x, mode=None): # RF classifier\n",
    "    if mode in (None, 'dev'): X_eval, Y_eval = X_dev, Y_dev\n",
    "    elif mode == 'test': X_eval, Y_eval = X_test, Y_test\n",
    "    elif mode == 'train': X_eval,  Y_eval = X_train, Y_train\n",
    "        \n",
    "    for i in range(0,len(x)):\n",
    "        x[i] = x[i] > 0.5\n",
    "    cols = []\n",
    "    for j in range(0, n):\n",
    "        if x[j] == 1:\n",
    "            cols.append(j)\n",
    "    z1_prime = extract_subset(X_train, cols)\n",
    "    z2_prime = extract_subset(X_eval, cols)\n",
    "    clf = RandomForestClassifier(n_jobs=2,random_state=0)\n",
    "    clf.fit(z1_prime, Y_train)\n",
    "    y_pred = clf.predict(z2_prime)\n",
    "    \n",
    "    acc = sklearn.metrics.accuracy_score(Y_eval,y_pred)\n",
    "    pre = sklearn.metrics.precision_score(Y_eval,y_pred)\n",
    "    fscore = sklearn.metrics.f1_score(Y_eval,y_pred)\n",
    "    recall = sklearn.metrics.recall_score(Y_eval,y_pred)\n",
    "    return acc,pre,fscore,recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_calc_fitness(x, mode=None): # KNN classifier\n",
    "    if mode in (None, 'dev'): X_eval, Y_eval = X_dev, Y_dev\n",
    "    elif mode == 'test': X_eval, Y_eval = X_test, Y_test\n",
    "    elif mode == 'train': X_eval,  Y_eval = X_train, Y_train\n",
    "\n",
    "    for i in range(0,len(x)):\n",
    "        x[i] = x[i] > 0.5\n",
    "    cols = []\n",
    "    for j in range(0, n):\n",
    "        if x[j] == 1:\n",
    "            cols.append(j)\n",
    "    z1_prime = extract_subset(X_train, cols)\n",
    "    z2_prime = extract_subset(X_eval, cols)\n",
    "    clf = KNN(3,weights='uniform')\n",
    "    clf.fit(z1_prime, Y_train)\n",
    "    y_pred = clf.predict(z2_prime)\n",
    "    \n",
    "    acc = sklearn.metrics.accuracy_score(Y_eval,y_pred)\n",
    "    pre = sklearn.metrics.precision_score(Y_eval,y_pred)\n",
    "    fscore = sklearn.metrics.f1_score(Y_eval,y_pred)\n",
    "    recall = sklearn.metrics.recall_score(Y_eval,y_pred)\n",
    "    return acc,pre,fscore,recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nb_calc_fitness(x, mode=None): # Gaussian NB (Naive Bayes) classifier\n",
    "    if mode in (None, 'dev'): X_eval, Y_eval = X_dev, Y_dev\n",
    "    elif mode == 'test': X_eval, Y_eval = X_test, Y_test\n",
    "    elif mode == 'train': X_eval,  Y_eval = X_train, Y_train\n",
    "    \n",
    "    for i in range(0,len(x)):\n",
    "        x[i] = x[i] > 0.5\n",
    "    cols = []\n",
    "    for j in range(0, n):\n",
    "        if x[j] == 1:\n",
    "            cols.append(j)\n",
    "    z1_prime = extract_subset(X_train, cols)\n",
    "    z2_prime = extract_subset(X_eval, cols)\n",
    "    clf = GNB()\n",
    "    clf.fit(z1_prime, Y_train)\n",
    "    y_pred = clf.predict(z2_prime)\n",
    "    \n",
    "    acc = sklearn.metrics.accuracy_score(Y_eval,y_pred)\n",
    "    pre = sklearn.metrics.precision_score(Y_eval,y_pred)\n",
    "    fscore = sklearn.metrics.f1_score(Y_eval,y_pred)\n",
    "    recall = sklearn.metrics.recall_score(Y_eval,y_pred)\n",
    "    return acc,pre,fscore,recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialise(m,n):\n",
    "    for i in range(0,m):\n",
    "        for j in range(0,n):\n",
    "            x = randint(0,1)\n",
    "            bat_pos[i].append(x)\n",
    "            bat_vel[i].append(0)\n",
    "\n",
    "        init_rate_vector.append(random.uniform(0, 1))\n",
    "\n",
    "        bat_frequency.append(init_rate_vector[i])\n",
    "        bat_loudness.append(random.uniform(1,2))\n",
    "        bat_rate.append(init_rate_vector[i])\n",
    "        bat_fitness.append(-infinity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def core():\n",
    "#     initialise(m,n)\n",
    "#     global_fit = -infinity\n",
    "#     for t in range (0,T):\n",
    "#         print(\"T:\" , t)\n",
    "#         for i in range(0,m):\n",
    "#             accuracy,pre,fscore,recall = svm_calc_fitness(bat_pos[i])\n",
    "#             '''\n",
    "#             with open(\"dumpPerformanceBat_svm_kpi.txt\", \"a\") as text_file:\n",
    "#                 text_file.write(\"{} {} {} {} {}\".format(accuracy,pre,fscore,recall,global_fit) + \"\\n\")\n",
    "#             with open(\"dumpPerformanceBat_svm.txt\", \"a\") as text_file:\n",
    "#                 text_file.write(\"{} {} {} {}\".format(t,accuracy,bat_pos[i].count(1),global_fit)+\"\\n\")\n",
    "#             #print(\"t={} accuracy={} #features={} global_fit={}\".format(t,accuracy,bat_pos[i].count(1),global_fit))\n",
    "#             '''\n",
    "#             acc = accuracy\n",
    "\n",
    "#             rand = randint(0,1)\n",
    "#             if rand < bat_loudness[i] and acc > bat_fitness[i]:\n",
    "#                 bat_fitness[i]=acc\n",
    "#                 bat_loudness[i]= alpha * bat_loudness[i]\n",
    "#                 bat_rate[i]= init_rate_vector[i] * (1 - math.exp(-(gamma * t)))\n",
    "\n",
    "#         maxindex,maxfit = max(enumerate(bat_fitness), key=operator.itemgetter(1))\n",
    "\n",
    "#         if maxfit>global_fit :\n",
    "#             global_fit = maxfit\n",
    "#             global_bat_pos = bat_pos[maxindex]\n",
    "\n",
    "#         for i in range(0,m): # for each bat\n",
    "#             beta = random.uniform(0,1)\n",
    "#             rand = random.uniform(0,1)\n",
    "#             AvgA = sum(bat_loudness)/len(bat_loudness)\n",
    "\n",
    "#             if rand > bat_rate[i] :\n",
    "#                 for j in range(0,n):\n",
    "#                     bat_pos[i][j] = bat_pos[i][j] + ( epsilon * AvgA )\n",
    "#                     sigma = randint(0,1)\n",
    "#                     if sigma < (1/(1+math.exp(-bat_pos[i][j]))) :\n",
    "#                         bat_pos[i][j]=1\n",
    "#                     else :\n",
    "#                         bat_pos[i][j]= 0\n",
    "\n",
    "#             rand = random.uniform(0,1)\n",
    "#             if rand < bat_loudness[i] and bat_fitness[i] < global_fit :\n",
    "#                 for j in range (0,n):\n",
    "#                     bat_frequency[i] = fmin + (fmax-fmin)* beta\n",
    "#                     bat_vel[i][j] = bat_vel[i][j] + (global_bat_pos[j]-bat_pos[i][j]) * bat_frequency[i]\n",
    "#                     bat_pos[i][j] = bat_pos[i][j] + bat_vel[i][j]\n",
    "#                     sigma = random.uniform(0,1)\n",
    "#                     if sigma < (1 / (1 + math.exp(-bat_pos[i][j]))) :\n",
    "#                         bat_pos[i][j]=1\n",
    "#                     else :\n",
    "#                         bat_pos[i][j]=0\n",
    "#         with open(\"dumpPerformanceBat_rf.txt\", \"a\") as text_file:\n",
    "#             text_file.write(\"{} {} {} \".format(t,global_bat_pos.count(1),global_fit)+\"\\n\")\n",
    "        \n",
    "\n",
    "\n",
    "#     feature_vector = global_bat_pos\n",
    "#     return feature_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def BAT_algo():\n",
    "#     feature_vector = core()\n",
    "#     return feature_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f = BAT_algo()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneticAlgorithm():\n",
    "    \n",
    "    def __init__(self, X_train, X_dev, Y_train, Y_dev, number_bits_to_mutate = 25.0):\n",
    "        \n",
    "        \n",
    "        self.toolbox = base.Toolbox()\n",
    "        self.ind_mut_pb = float(number_bits_to_mutate / X_train.shape[1])\n",
    "        self.NGEN = 100\n",
    "        self.MUTPB = 0.2\n",
    "        self.CXPB = 0.5\n",
    "        self.POPULATION_SIZE = 70\n",
    "        self.NUMBER_TO_SELECT_FROM_POP = 35\n",
    "        self.init_pop = list()\n",
    "        self.X_train = X_train\n",
    "        self.X_dev = X_dev\n",
    "        self.Y_train = Y_train\n",
    "        self.Y_dev = Y_dev\n",
    "        \n",
    "    \n",
    "    def initialise_toolbox(self):\n",
    "        print('now initializing toolbox GA1')\n",
    "        # I want to maximize session overlap as well as length\n",
    "        creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
    "        # representing individual as a list\n",
    "        creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
    "        # individual will be a list of 0/1\n",
    "        self.toolbox.register(\"attr_bool\", random.randint, 0, 1)\n",
    "        IND_DIMENSIONALITY = self.X_train.shape[1]\n",
    "        # create template for individual\n",
    "        self.toolbox.register(\"individual\", tools.initRepeat, creator.Individual, self.toolbox.attr_bool, n=IND_DIMENSIONALITY)\n",
    "        #self.toolbox.register(\"individual\", tools.initIterate, creator.Individual, self.get_ind)\n",
    "        # create template for population\n",
    "        self.toolbox.register(\"population\", tools.initRepeat, list, self.toolbox.individual)\n",
    "        print('toolbox initialised')\n",
    "    \n",
    "    \n",
    "    def initialise_fitness_function(self):\n",
    "        print('building and registering the fitness function')\n",
    "        \n",
    "        def fitness(individual):\n",
    "            \n",
    "            \n",
    "            accuracy,pre,fscore,recall = svm_calc_fitness(individual)\n",
    "            return fscore,\n",
    "            \n",
    "        \n",
    "        self.toolbox.register(\"evaluate\", lambda individual: fitness(individual))\n",
    "        self.toolbox.register(\"mate\", tools.cxOnePoint)\n",
    "        self.toolbox.register(\"mutate\", tools.mutFlipBit, indpb=self.MUTPB)\n",
    "        self.toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
    "        \n",
    "        print('fitness function ready')\n",
    "    \n",
    "    def run_algorithm(self):\n",
    "        \n",
    "        self.initialise_toolbox()\n",
    "        self.initialise_fitness_function()\n",
    "        \n",
    "        print('mutation probability was calculated at %f' % self.ind_mut_pb)\n",
    "        print('running the algorithm')\n",
    "        toolbox = self.toolbox\n",
    "        # create a population of size n\n",
    "        pop = toolbox.population(n=self.POPULATION_SIZE)\n",
    "        \n",
    "        \n",
    "        for gen in range(self.NGEN):\n",
    "            # Select the next generation individuals\n",
    "            if gen%5 == 0:\n",
    "                print(gen)\n",
    "            offspring = toolbox.select(pop, len(pop))\n",
    "            \n",
    "            for ind in offspring:\n",
    "                if ind.fitness.valid:\n",
    "                    pass\n",
    "            # Clone the selected individuals\n",
    "            offspring = list(map(toolbox.clone, offspring))\n",
    "\n",
    "            # Apply crossover on the offspring\n",
    "            for child1, child2 in zip(offspring[::2], offspring[1::2]):\n",
    "                if random.random() < self.CXPB:\n",
    "                    #toolbox.mate(child1, child2)\n",
    "                    tools.cxUniform(child1, child2, 0.5)\n",
    "                    del child1.fitness.values\n",
    "                    del child2.fitness.values\n",
    "\n",
    "            # Apply mutation on the offspring\n",
    "            for mutant in offspring:\n",
    "                if random.random() < self.MUTPB:\n",
    "                    # print('now doing mutation')\n",
    "                    toolbox.mutate(mutant)\n",
    "                    del mutant.fitness.values\n",
    "\n",
    "            # Evaluate the individuals with an invalid fitness\n",
    "            invalid_ind = [ind for ind in offspring if not ind.fitness.valid]\n",
    "            fitnesses = toolbox.map(toolbox.evaluate, invalid_ind)\n",
    "            \n",
    "            added = 0\n",
    "            for ind, fit in zip(invalid_ind, fitnesses):\n",
    "                ind.fitness.values = fit\n",
    "                \n",
    "\n",
    "            # The population is entirely replaced by the offspring\n",
    "            pop[:] = offspring\n",
    "            top = tools.selBest(pop, k=self.NUMBER_TO_SELECT_FROM_POP)\n",
    "            \n",
    "            # Dump best individual to file\n",
    "            fittest = tools.selBest(pop, k=1)[0]\n",
    "            count = 0\n",
    "            for i in range(0, len(fittest)):\n",
    "                if fittest[i] == 1:\n",
    "                    count = count + 1\n",
    "            with open(\"GA_performance.txt\", \"a\") as text_file:\n",
    "                accuracy,prec,fscore,recall = svm_calc_fitness(fittest)\n",
    "                text_file.write(\"{} {}\".format(count,fittest.fitness.values[0])+\"\\n\")\n",
    "                print(count,accuracy,prec,fscore,recall,fittest.fitness.values[0])\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        max_fitness = float(\"-inf\")\n",
    "        \n",
    "        for individual in tools.selBest(pop, k=1):\n",
    "            if individual.fitness.valid:\n",
    "                if individual.fitness.values[0] > max_fitness:\n",
    "                    max_fitness = individual.fitness.values[0]\n",
    "                    fittest_individual = individual\n",
    "                    \n",
    "        count = 0\n",
    "        for i in range(0, len(fittest_individual)):\n",
    "            if fittest_individual[i] == 1:\n",
    "                count = count + 1        \n",
    "        \n",
    "        print(count, max_fitness)\n",
    "        return fittest_individual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ga = GeneticAlgorithm(X_train, X_dev, Y_train, Y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now initializing toolbox GA1\n",
      "toolbox initialised\n",
      "building and registering the fitness function\n",
      "fitness function ready\n",
      "mutation probability was calculated at 0.002940\n",
      "running the algorithm\n",
      "0\n",
      "4232 0.7696969696969697 0.7961165048543689 0.6833333333333333 0.5985401459854015 0.6833333333333333\n",
      "4213 0.7777777777777778 0.7850746268656716 0.7050938337801608 0.6399026763990268 0.7050938337801608\n",
      "4213 0.7777777777777778 0.7850746268656716 0.7050938337801608 0.6399026763990268 0.7050938337801608\n",
      "4206 0.7787878787878788 0.7840236686390533 0.7076101468624834 0.6447688564476886 0.7076101468624834\n",
      "4243 0.7818181818181819 0.7876106194690266 0.7119999999999999 0.6496350364963503 0.7119999999999999\n",
      "5\n",
      "4194 0.798989898989899 0.823170731707317 0.7307171853856563 0.656934306569343 0.7307171853856563\n",
      "4194 0.798989898989899 0.823170731707317 0.7307171853856563 0.656934306569343 0.7307171853856563\n",
      "4223 0.804040404040404 0.838006230529595 0.7349726775956283 0.6545012165450121 0.7349726775956283\n",
      "4226 0.797979797979798 0.8130563798219584 0.732620320855615 0.6666666666666666 0.732620320855615\n",
      "4241 0.802020202020202 0.8171091445427728 0.7386666666666666 0.6739659367396593 0.7386666666666666\n",
      "10\n",
      "4212 0.802020202020202 0.8152492668621701 0.7393617021276596 0.6763990267639902 0.7393617021276596\n",
      "4211 0.8010101010101011 0.8057142857142857 0.7411300919842313 0.6861313868613139 0.7411300919842313\n",
      "4211 0.8010101010101011 0.8057142857142857 0.7411300919842313 0.6861313868613139 0.7411300919842313\n",
      "4206 0.806060606060606 0.8192419825072886 0.7453580901856763 0.683698296836983 0.7453580901856763\n",
      "4228 0.8121212121212121 0.8205128205128205 0.7559055118110237 0.7007299270072993 0.7559055118110237\n",
      "15\n",
      "4228 0.8121212121212121 0.8205128205128205 0.7559055118110237 0.7007299270072993 0.7559055118110237\n",
      "4212 0.8121212121212121 0.8242074927953891 0.7546174142480211 0.6958637469586375 0.7546174142480211\n",
      "4212 0.8121212121212121 0.8242074927953891 0.7546174142480211 0.6958637469586375 0.7546174142480211\n",
      "4228 0.8131313131313131 0.8228571428571428 0.7568988173455978 0.7007299270072993 0.7568988173455978\n",
      "4213 0.8181818181818182 0.8290598290598291 0.7637795275590552 0.708029197080292 0.7637795275590552\n",
      "20\n",
      "4176 0.8202020202020202 0.830028328611898 0.7670157068062827 0.7128953771289538 0.7670157068062827\n",
      "4176 0.8202020202020202 0.830028328611898 0.7670157068062827 0.7128953771289538 0.7670157068062827\n",
      "4176 0.8202020202020202 0.830028328611898 0.7670157068062827 0.7128953771289538 0.7670157068062827\n",
      "4176 0.8202020202020202 0.830028328611898 0.7670157068062827 0.7128953771289538 0.7670157068062827\n",
      "4192 0.8222222222222222 0.836676217765043 0.7684210526315789 0.7104622871046229 0.7684210526315789\n",
      "25\n",
      "4209 0.8252525252525252 0.8459302325581395 0.7708609271523179 0.708029197080292 0.7708609271523179\n",
      "4204 0.8242424242424242 0.8338028169014085 0.7728459530026109 0.7201946472019465 0.7728459530026109\n",
      "4204 0.8242424242424242 0.8338028169014085 0.7728459530026109 0.7201946472019465 0.7728459530026109\n",
      "4202 0.8282828282828283 0.8452722063037249 0.7763157894736843 0.7177615571776156 0.7763157894736843\n",
      "4202 0.8282828282828283 0.8452722063037249 0.7763157894736843 0.7177615571776156 0.7763157894736843\n",
      "30\n",
      "4202 0.8282828282828283 0.8452722063037249 0.7763157894736843 0.7177615571776156 0.7763157894736843\n",
      "4187 0.8282828282828283 0.8375350140056023 0.7786458333333333 0.7274939172749392 0.7786458333333333\n",
      "4187 0.8282828282828283 0.8375350140056023 0.7786458333333333 0.7274939172749392 0.7786458333333333\n",
      "4246 0.8292929292929293 0.8418079096045198 0.7790849673202616 0.7250608272506083 0.7790849673202616\n",
      "4215 0.8313131313131313 0.840782122905028 0.7828348504551366 0.732360097323601 0.7828348504551366\n",
      "35\n",
      "4206 0.8323232323232324 0.8431372549019608 0.7838541666666666 0.732360097323601 0.7838541666666666\n",
      "4202 0.8333333333333334 0.847457627118644 0.7843137254901961 0.7299270072992701 0.7843137254901961\n",
      "4202 0.8353535353535354 0.848314606741573 0.78748370273794 0.7347931873479319 0.78748370273794\n",
      "4202 0.8353535353535354 0.848314606741573 0.78748370273794 0.7347931873479319 0.78748370273794\n",
      "4202 0.8353535353535354 0.848314606741573 0.78748370273794 0.7347931873479319 0.78748370273794\n",
      "40\n",
      "4229 0.8353535353535354 0.8463687150837989 0.788036410923277 0.7372262773722628 0.788036410923277\n",
      "4199 0.8363636363636363 0.8467966573816156 0.7896103896103895 0.7396593673965937 0.7896103896103895\n",
      "4227 0.8363636363636363 0.8467966573816156 0.7896103896103895 0.7396593673965937 0.7896103896103895\n",
      "4227 0.8363636363636363 0.8467966573816156 0.7896103896103895 0.7396593673965937 0.7896103896103895\n",
      "4229 0.8383838383838383 0.8515406162464986 0.7916666666666665 0.7396593673965937 0.7916666666666665\n",
      "45\n",
      "4197 0.8383838383838383 0.8515406162464986 0.7916666666666665 0.7396593673965937 0.7916666666666665\n",
      "4197 0.8383838383838383 0.8515406162464986 0.7916666666666665 0.7396593673965937 0.7916666666666665\n",
      "4215 0.8393939393939394 0.8519553072625698 0.7932379713914173 0.7420924574209246 0.7932379713914173\n",
      "4212 0.8393939393939394 0.8519553072625698 0.7932379713914173 0.7420924574209246 0.7932379713914173\n",
      "4229 0.8393939393939394 0.8519553072625698 0.7932379713914173 0.7420924574209246 0.7932379713914173\n",
      "50\n",
      "4229 0.8393939393939394 0.8519553072625698 0.7932379713914173 0.7420924574209246 0.7932379713914173\n",
      "4229 0.8393939393939394 0.8519553072625698 0.7932379713914173 0.7420924574209246 0.7932379713914173\n",
      "4229 0.8393939393939394 0.8519553072625698 0.7932379713914173 0.7420924574209246 0.7932379713914173\n",
      "4211 0.8404040404040404 0.8543417366946778 0.7942708333333333 0.7420924574209246 0.7942708333333333\n",
      "4236 0.8404040404040404 0.8543417366946778 0.7942708333333333 0.7420924574209246 0.7942708333333333\n",
      "55\n",
      "4225 0.8404040404040404 0.8543417366946778 0.7942708333333333 0.7420924574209246 0.7942708333333333\n",
      "4222 0.8404040404040404 0.8543417366946778 0.7942708333333333 0.7420924574209246 0.7942708333333333\n",
      "4228 0.8404040404040404 0.8543417366946778 0.7942708333333333 0.7420924574209246 0.7942708333333333\n",
      "4226 0.8404040404040404 0.8543417366946778 0.7942708333333333 0.7420924574209246 0.7942708333333333\n",
      "4222 0.8404040404040404 0.8543417366946778 0.7942708333333333 0.7420924574209246 0.7942708333333333\n",
      "60\n",
      "4211 0.8404040404040404 0.8543417366946778 0.7942708333333333 0.7420924574209246 0.7942708333333333\n",
      "4228 0.8404040404040404 0.8543417366946778 0.7942708333333333 0.7420924574209246 0.7942708333333333\n",
      "4238 0.8404040404040404 0.8543417366946778 0.7942708333333333 0.7420924574209246 0.7942708333333333\n",
      "4225 0.8404040404040404 0.8543417366946778 0.7942708333333333 0.7420924574209246 0.7942708333333333\n",
      "4242 0.8404040404040404 0.8543417366946778 0.7942708333333333 0.7420924574209246 0.7942708333333333\n",
      "65\n",
      "4242 0.8404040404040404 0.8543417366946778 0.7942708333333333 0.7420924574209246 0.7942708333333333\n",
      "4237 0.8404040404040404 0.8543417366946778 0.7942708333333333 0.7420924574209246 0.7942708333333333\n",
      "4220 0.8404040404040404 0.8543417366946778 0.7942708333333333 0.7420924574209246 0.7942708333333333\n",
      "4227 0.8404040404040404 0.8543417366946778 0.7942708333333333 0.7420924574209246 0.7942708333333333\n",
      "4225 0.8404040404040404 0.8543417366946778 0.7942708333333333 0.7420924574209246 0.7942708333333333\n",
      "70\n",
      "4235 0.8404040404040404 0.8543417366946778 0.7942708333333333 0.7420924574209246 0.7942708333333333\n",
      "4236 0.8404040404040404 0.8543417366946778 0.7942708333333333 0.7420924574209246 0.7942708333333333\n",
      "4224 0.8404040404040404 0.8543417366946778 0.7942708333333333 0.7420924574209246 0.7942708333333333\n",
      "4232 0.8404040404040404 0.8543417366946778 0.7942708333333333 0.7420924574209246 0.7942708333333333\n",
      "4228 0.8404040404040404 0.8543417366946778 0.7942708333333333 0.7420924574209246 0.7942708333333333\n",
      "75\n",
      "4232 0.8404040404040404 0.8543417366946778 0.7942708333333333 0.7420924574209246 0.7942708333333333\n",
      "4226 0.8404040404040404 0.8543417366946778 0.7942708333333333 0.7420924574209246 0.7942708333333333\n",
      "4227 0.8404040404040404 0.8543417366946778 0.7942708333333333 0.7420924574209246 0.7942708333333333\n",
      "4224 0.8404040404040404 0.8543417366946778 0.7942708333333333 0.7420924574209246 0.7942708333333333\n",
      "4227 0.8404040404040404 0.8543417366946778 0.7942708333333333 0.7420924574209246 0.7942708333333333\n",
      "80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4233 0.8404040404040404 0.8543417366946778 0.7942708333333333 0.7420924574209246 0.7942708333333333\n",
      "4237 0.8404040404040404 0.8543417366946778 0.7942708333333333 0.7420924574209246 0.7942708333333333\n",
      "4226 0.8404040404040404 0.8543417366946778 0.7942708333333333 0.7420924574209246 0.7942708333333333\n",
      "4236 0.8404040404040404 0.8543417366946778 0.7942708333333333 0.7420924574209246 0.7942708333333333\n",
      "4230 0.8404040404040404 0.8543417366946778 0.7942708333333333 0.7420924574209246 0.7942708333333333\n",
      "85\n",
      "4237 0.8404040404040404 0.8543417366946778 0.7942708333333333 0.7420924574209246 0.7942708333333333\n",
      "4230 0.8404040404040404 0.8543417366946778 0.7942708333333333 0.7420924574209246 0.7942708333333333\n",
      "4224 0.8404040404040404 0.8543417366946778 0.7942708333333333 0.7420924574209246 0.7942708333333333\n",
      "4228 0.8404040404040404 0.8543417366946778 0.7942708333333333 0.7420924574209246 0.7942708333333333\n",
      "4226 0.8404040404040404 0.8543417366946778 0.7942708333333333 0.7420924574209246 0.7942708333333333\n",
      "90\n",
      "4238 0.8404040404040404 0.8543417366946778 0.7942708333333333 0.7420924574209246 0.7942708333333333\n",
      "4240 0.8404040404040404 0.8543417366946778 0.7942708333333333 0.7420924574209246 0.7942708333333333\n",
      "4233 0.8404040404040404 0.8543417366946778 0.7942708333333333 0.7420924574209246 0.7942708333333333\n",
      "4229 0.8404040404040404 0.8543417366946778 0.7942708333333333 0.7420924574209246 0.7942708333333333\n",
      "4231 0.8404040404040404 0.8543417366946778 0.7942708333333333 0.7420924574209246 0.7942708333333333\n",
      "95\n",
      "4231 0.8404040404040404 0.8543417366946778 0.7942708333333333 0.7420924574209246 0.7942708333333333\n",
      "4233 0.8404040404040404 0.8543417366946778 0.7942708333333333 0.7420924574209246 0.7942708333333333\n",
      "4228 0.8404040404040404 0.8543417366946778 0.7942708333333333 0.7420924574209246 0.7942708333333333\n",
      "4231 0.8404040404040404 0.8543417366946778 0.7942708333333333 0.7420924574209246 0.7942708333333333\n",
      "4235 0.8404040404040404 0.8543417366946778 0.7942708333333333 0.7420924574209246 0.7942708333333333\n",
      "4235 0.7942708333333333\n"
     ]
    }
   ],
   "source": [
    "fittest_individual = ga.run_algorithm()\n",
    "# takes ~2s per generation (for population of size 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'11111010000111100101001011110011110010110101000000100000011011111011011100110000000011010111011000100001000100010010000011010001100001010101011001111011101011110000111100000100011110001011101000101001000110111111010001001110100011011101101101101011011000100110111111011101011000101110001001101010010100111110011011011101101101110111000110000111010101110001100111101111010101100100110000010000101100010001101101011011001101100010000000110011101111001100011000111100110111100100001111110111010001110011100000111110111100011010110110010001010101100011101100000111110011001000111010111011100100100101000110110010111110100110101101000011001100110100111010001000111110110011110111101100001000001000011000110000100101111110010000100111001111010101101110101001001101000111001100010111100111101011001101001111100010100000101111001100101110011100000110000011001101000100000100010111010000100111011101010011101000111101100000111111100011010011101001110001010010011011110001001010110011011100110110000011111001101111110000001101001100001111010110000000100111100001001110111000110001001001110010100110011010010101011111010001101110010101111011000100001000110001100010001010011000000101100111100111010000011100011011110000100100001101111010100011010100110001110110101101010000011011001101100111110100001101001000010011100011000111001000101000001001010011000100110111000010001100000000101110000001110101010011001111110100111101101000101001001110101010010010100100010010010011100111111100101100100111010101110110011100101000010010001101010011010000010011011110110100011110100001000101001010011001100000100100111001111000100001100010010001100011110011001101000100110101001100100000110000100010111111101111011011111001010101010000001101101111110011010111011101010011100001001001111101010001010010100010101101100001100110011011010010101000110000110001111000010101111111001000111010001110011100110010100000101000001001111100010001010111010000101101100101111111011000000010000101000110011110011001100000011001111001010000111010111111110100010101000000110101111001001101100001111001101010111001010100110101100010011100100101111010100001001000000011101110011001011110100010001101101100110100000000000011111100001111111111010000111100110010010000111111101111111010000100010001101011110011110101101010000101111111100010000011100001100110010111000100110110001111001001110011111100011010110000100100100000110000111100111011011001000111100111100101001101000000100100000000101001110101101100010101111011001110111000000110011101110100110000001100011001101100100000001111001001000110000000010010010100110101101000011101000101111001110101101111100011010100000111010010111110010001111001110100110110100001110111010101011101110100001011010010000000011000011011101001010101011100101101110000110000111001111100100100010101011010010111100100011001101011011010000000010010111010110000101100111001001110110101011110101110100011100111110100000001101101011000000001010111001010011100101101000110100010101110000000111010111001001101000001001110000111111111110101011111011101110011010101100101001001110001001010111111110100010100100000111010110111111010010010101000110001111000110111100001001010111110011011111110111010101111001001111000000010010000110011010100011000000000101000010011111011100110100110111100011010011000101010000111110100010011000101001100111111100011110001110110001100100101110001010111110001101011000011010111100001010011010110101111000010111010111000001101000111010110101101010110100010111000111001101110100100111011111100100101111010011101110010010100010001100100100110010011001000100001000111100000010001110111101010110000010010000010010100001010110001011001111001011110010001101011010000101111001111101011011001100001111000001001110111110000000110000011011010110111111001010100100010010011110001001011101010010001101101110110101001010111011010010101001000010000101101000000010011011110001011101011010000100101001111000111010110011000100010101111001001110111001001101001010011010001100001011001001101001001010111110110001011110001000001101111110100110101010000001010111100101010110010000100101001110100110111000101010000110010111100011111101000001011110101100110110111000110101101110010111011001011000111010000111001000100010011110011100011110100001110001101111001101110111111100010011010101001101110100110101110001111101111100101111001100010111010000010111101010111010101110011100000101110010100011111101011100101100110111000010010100011011001000100000110101011011111111010101001101011110100111010000000011100100110110100101110011100110111010110101100001100000101111000100110111111101011001111100110001000011011101100101111100000010100101100111010100001101101000100001000110010111101100011001011011100011010000110010011100011110100110011100011000000101101100110010101010010110001101010010010101101000001000001111111110100100001011011000101100100010101000000001111111001010001101110000010000110000001100111110001000111011001010100110000001111110110011100110010101111101111100011100100011010110011001111111101011100010101010001010011010010111000101011110111100000111100101000110101010011100111100000000101010100100110011101011110110011001011101011010000110010000010010101110110101111110111100000101001110100100000010110011101111010110011011010000000000100101001110010010111000000011011110101010100100100100011001110100101000011110111100111010100110110010011011010001111100101101101110010110100000011111101110000111011000001001101101011100001000100001110010010000110101010011100100110010100010110111110000000011100001011111010010101101100110100110001101000001010011001011011101001101011000010110010010111101000111010011010011101001010001110010011101101010011101110100110001110010110100110110010110000010001110111001011001100100101010111111100100000111001001111110011011011000111010100101111010110101100010111100110100101000100010000110100011111110100111101011001110111111110011100010001000111001101010011101011000010110110110101110111011011110011100010101000110010111010111100000000011011000100000010111100000111100100100101001101011101010101001111110010111111101010101111001011000001110011011101100000110000001001011011110010001000000110110001011111011100010010001101001010100001010000110010101011100000001110110111010100000101110001001010101101000111001110100111000101011011101011001100111010110111010011011110110011110001011010010010001111110000000100111000000111111100000011101000100000011101000111110101111010100011000100011110100000001010011010001010000111011111001011001110110110111010100010110100110001110110001001000001100011110110110000110111110111100101100001010111011101101000011111010011110110010001011001110000000101111010001000110111001100000100110100110100111000101011010010001000001010111101111001100011111101010110110100011001111000111001010110001111000010000011010001011010110101110100000100100111101010010111111111110010000111111000000011101101011110101001111001010111111010011011010011000111010000010100010110111101101110111010101100111011101101110011100000100111010110100110000100001000011100101011001110100001101101111010000011001101011101010100111011011010011011100000100010010111010100100000101111011101001000001000011100100001000100100001110100100000000101010110000001010000111001010110101011111100100111011011010000110010100010011111000100001010110011101010011111000110110100010100000010101011100011011100101011000000100101010011100011011101100101011111011101111001110101101001110010000110101111000101010010000000110000100001001110110010001110011100100100000101111000011110011001101100001111111111101001001011111110010101100100110111011111010001110011111100011011111011010000000110101111101010000011101110100110110111010101111111101010000011111101001101100010101001111100111001100011011101011100110111110001100101100100111000101101111100111111111001110011101000101000010010010110011100101110010000000001100010101010010010010100011010111110011101000110101100001101011110011000000101100010110110011010100010010011100100010100111010111110100101101011011111000010111011110111000011000110110000001000010111101010010110010100001110101110001111101001001010010111100000101111110101001100011000010001100000111011010110101010101111000111010110001110010010011000000000000100001101001110100100111101110011011111101110011100010011000100010001110001011100110000001011010111101100010001011110101100100111111000110000001100001100100011000111010110010100100000010001111000001001101110001110110001101000011111010010111110110111110100000101010100001100000101000011101111001010100010011010010001101011001110011100000001'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fittest_individual # List[Boolean]\n",
    "''.join([str(int(x)) for x in fittest_individual])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8404040404040404,\n",
       " 0.8543417366946778,\n",
       " 0.7942708333333333,\n",
       " 0.7420924574209246)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# devset\n",
    "acc, pre, fscore, recall = svm_calc_fitness(fittest_individual)\n",
    "acc, pre, fscore, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8036449147560258, 0.799625468164794, 0.7188552188552189, 0.6529051987767585)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testset\n",
    "acc, pre, fscore, recall = svm_calc_fitness(fittest_individual, mode='test')\n",
    "acc, pre, fscore, recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code Flow\n",
    "- Feature extraction from the corpus (uni, bi, tri, tf-idf, lda, pos, nrc)\n",
    "- GA (meta-heuristic) for feature selection\n",
    "  - population of individuals, where each individual corresponds to a bitmask of features to select\n",
    "  - individuals evolve over the generations by cross-over and mutation\n",
    "  - fitness of individuals is evaluated using F1 score (this score is calculated on devset by fitting the model with a small amount of trainset for guiding GA)\n",
    "  - after GA finishes, we end up we the fittest individual ie the optimal feature set (denoted by a bitmask) (giving a good reduction of 50%)\n",
    "- Finally we train our model on the complete training set based on the selected features and evaluate it on testset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
