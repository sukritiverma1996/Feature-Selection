{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "from random import randint\n",
    "import random\n",
    "import math\n",
    "from collections import defaultdict\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import svm\n",
    "import operator\n",
    "import sklearn.metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "from sklearn.naive_bayes import GaussianNB as GNB\n",
    "from pandas import DataFrame, read_csv\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from deap import creator, base, tools, algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         Description  Category\n",
      "0  Was walking along crowded street, holding mums...         0\n",
      "1  This incident took place in the evening.I was ...         1\n",
      "2  I WAS WAITING FOR THE BUS. A MAN CAME ON A BIK...         0\n",
      "3                 Incident happened inside the train         0\n",
      "4  I witnessed an incident when a chain was bruta...         0\n"
     ]
    }
   ],
   "source": [
    "file1 = '../../../data/safecity/binary/ogling/train.csv'\n",
    "df = pd.read_csv(file1)\n",
    "print(df.head())\n",
    "\n",
    "corpus = list(df[\"Description\"])\n",
    "target = list(df[\"Category\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# infinity = float(\"inf\") #sentinel maximum value\n",
    "# m = 70 #no of bats (50-70)\n",
    "# T = 100 # no of iterations(100)\n",
    "\n",
    "# bat_pos = defaultdict(list)\n",
    "# bat_vel = defaultdict(list)\n",
    "# bat_loudness = []\n",
    "# bat_rate = []\n",
    "# bat_fitness = []\n",
    "# bat_frequency = []\n",
    "\n",
    "# global_bat_pos = []\n",
    "# init_rate_vector = []\n",
    "# feature_vector = []\n",
    "\n",
    "# #hyperparameters\n",
    "# alpha = 0.9\n",
    "# gamma = 0.9\n",
    "# epsilon = random.uniform(-1,1)\n",
    "# fmin=0\n",
    "# fmax =1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7201, 8504)\n",
      "['00', '000', '00am', '00pm', '01', '03', '0300', '05', '06', '0740', '0800am', '0830', '08826862360', '0900', '0930', '0f', '10', '100', '1000', '1000am', '1011am', '1012', '1015', '1030', '1030am', '1030ish', '1030pm', '1050', '10pm', '10th', '11', '1115', '1130', '1139', '1150', '11am', '11h', '11th', '12', '1213', '1214', '1230', '1245', '12th', '12yearold', '12years', '12yrs', '13', '1314', '13th']\n",
      "8504\n",
      "                                         Description  Category\n",
      "0  Buses approaching to this place is highly unsafe.         0\n",
      "1                        a man was commenting at me.         0\n",
      "2                                    in a share auto         0\n",
      "3  I was coming out of a club at night with a few...         0\n",
      "4  One of my friends was molested in the crowd. T...         0\n",
      "(990, 8504)\n",
      "['00', '000', '00am', '00pm', '01', '03', '0300', '05', '06', '0740', '0800am', '0830', '08826862360', '0900', '0930', '0f', '10', '100', '1000', '1000am', '1011am', '1012', '1015', '1030', '1030am', '1030ish', '1030pm', '1050', '10pm', '10th', '11', '1115', '1130', '1139', '1150', '11am', '11h', '11th', '12', '1213', '1214', '1230', '1245', '12th', '12yearold', '12years', '12yrs', '13', '1314', '13th']\n",
      "8504\n",
      "                                         Description  Category\n",
      "0  During morning, a woman was walking by and thi...         1\n",
      "1  A man tried to brush his penis off of a woman'...         0\n",
      "2  This happened to a fellow passenger of mine tr...         1\n",
      "3                                             ogling         1\n",
      "4  When I was returning my home after finishing m...         0\n",
      "(1701, 8504)\n",
      "['00', '000', '00am', '00pm', '01', '03', '0300', '05', '06', '0740', '0800am', '0830', '08826862360', '0900', '0930', '0f', '10', '100', '1000', '1000am', '1011am', '1012', '1015', '1030', '1030am', '1030ish', '1030pm', '1050', '10pm', '10th', '11', '1115', '1130', '1139', '1150', '11am', '11h', '11th', '12', '1213', '1214', '1230', '1245', '12th', '12yearold', '12years', '12yrs', '13', '1314', '13th']\n",
      "8504\n"
     ]
    }
   ],
   "source": [
    "#do once\n",
    "# nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1, 1), stop_words=stop_words)\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "print(X.shape)\n",
    "print(vectorizer.get_feature_names()[0:50])\n",
    "print(len(vectorizer.get_feature_names()))\n",
    "\n",
    "X_train = X\n",
    "Y_train = target\n",
    "\n",
    "file2 = '../../../data/safecity/binary/ogling/dev.csv'\n",
    "df_dev = pd.read_csv(file2)\n",
    "print(df_dev.head())\n",
    "corpus_dev = list(df_dev[\"Description\"])\n",
    "target_dev = list(df_dev[\"Category\"])\n",
    "X_dev = vectorizer.transform(corpus_dev)\n",
    "print(X_dev.shape)\n",
    "print(vectorizer.get_feature_names()[0:50])\n",
    "print(len(vectorizer.get_feature_names()))\n",
    "Y_dev = target_dev\n",
    "\n",
    "file3 = '../../../data/safecity/binary/ogling/test.csv'\n",
    "df_test = pd.read_csv(file3)\n",
    "print(df_test.head())\n",
    "corpus_test = list(df_test[\"Description\"])\n",
    "target_test = list(df_test[\"Category\"])\n",
    "X_test = vectorizer.transform(corpus_test)\n",
    "print(X_test.shape)\n",
    "print(vectorizer.get_feature_names()[0:50])\n",
    "print(len(vectorizer.get_feature_names()))\n",
    "Y_test = target_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7201, 8504) (990, 8504)\n"
     ]
    }
   ],
   "source": [
    "z1, z2 = X_train, X_dev\n",
    "print(z1.shape, z2.shape)\n",
    "n = z1.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#auxillary  functions\n",
    "def extract_subset(z,cols):\n",
    "    return z[:,cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svm_calc_fitness(x, mode=None): # SVM classifier\n",
    "    if mode in (None, 'dev'): X_eval, Y_eval = X_dev, Y_dev\n",
    "    elif mode == 'test': X_eval, Y_eval = X_test, Y_test\n",
    "    elif mode == 'train': X_eval,  Y_eval = X_train, Y_train\n",
    "        \n",
    "    for i in range(0,len(x)):\n",
    "        x[i] = x[i] > 0.5\n",
    "    cols = []\n",
    "    for j in range(0, n):\n",
    "        if x[j] == 1:\n",
    "            cols.append(j)\n",
    "    z1_prime = extract_subset(X_train, cols)\n",
    "    z2_prime = extract_subset(X_eval, cols)\n",
    "    clf = svm.LinearSVC(C=1.0)\n",
    "    clf.fit(z1_prime, Y_train)\n",
    "    y_pred = clf.predict(z2_prime)\n",
    "    \n",
    "    acc = sklearn.metrics.accuracy_score(Y_eval,y_pred)\n",
    "    pre = sklearn.metrics.precision_score(Y_eval,y_pred)\n",
    "    fscore = sklearn.metrics.f1_score(Y_eval,y_pred)\n",
    "    recall = sklearn.metrics.recall_score(Y_eval,y_pred)\n",
    "    return acc,pre,fscore,recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf_calc_fitness(x, mode=None): # RF classifier\n",
    "    if mode in (None, 'dev'): X_eval, Y_eval = X_dev, Y_dev\n",
    "    elif mode == 'test': X_eval, Y_eval = X_test, Y_test\n",
    "    elif mode == 'train': X_eval,  Y_eval = X_train, Y_train\n",
    "        \n",
    "    for i in range(0,len(x)):\n",
    "        x[i] = x[i] > 0.5\n",
    "    cols = []\n",
    "    for j in range(0, n):\n",
    "        if x[j] == 1:\n",
    "            cols.append(j)\n",
    "    z1_prime = extract_subset(X_train, cols)\n",
    "    z2_prime = extract_subset(X_eval, cols)\n",
    "    clf = RandomForestClassifier(n_estimators=100, n_jobs=10, random_state=0)\n",
    "    clf.fit(z1_prime, Y_train)\n",
    "    y_pred = clf.predict(z2_prime)\n",
    "    \n",
    "    acc = sklearn.metrics.accuracy_score(Y_eval,y_pred)\n",
    "    pre = sklearn.metrics.precision_score(Y_eval,y_pred)\n",
    "    fscore = sklearn.metrics.f1_score(Y_eval,y_pred)\n",
    "    recall = sklearn.metrics.recall_score(Y_eval,y_pred)\n",
    "    return acc,pre,fscore,recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_calc_fitness(x, mode=None): # KNN classifier\n",
    "    if mode in (None, 'dev'): X_eval, Y_eval = X_dev, Y_dev\n",
    "    elif mode == 'test': X_eval, Y_eval = X_test, Y_test\n",
    "    elif mode == 'train': X_eval,  Y_eval = X_train, Y_train\n",
    "\n",
    "    for i in range(0,len(x)):\n",
    "        x[i] = x[i] > 0.5\n",
    "    cols = []\n",
    "    for j in range(0, n):\n",
    "        if x[j] == 1:\n",
    "            cols.append(j)\n",
    "    z1_prime = extract_subset(X_train, cols)\n",
    "    z2_prime = extract_subset(X_eval, cols)\n",
    "    clf = KNN(3,weights='uniform')\n",
    "    clf.fit(z1_prime, Y_train)\n",
    "    y_pred = clf.predict(z2_prime)\n",
    "    \n",
    "    acc = sklearn.metrics.accuracy_score(Y_eval,y_pred)\n",
    "    pre = sklearn.metrics.precision_score(Y_eval,y_pred)\n",
    "    fscore = sklearn.metrics.f1_score(Y_eval,y_pred)\n",
    "    recall = sklearn.metrics.recall_score(Y_eval,y_pred)\n",
    "    return acc,pre,fscore,recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nb_calc_fitness(x, mode=None): # Gaussian NB (Naive Bayes) classifier\n",
    "    if mode in (None, 'dev'): X_eval, Y_eval = X_dev, Y_dev\n",
    "    elif mode == 'test': X_eval, Y_eval = X_test, Y_test\n",
    "    elif mode == 'train': X_eval,  Y_eval = X_train, Y_train\n",
    "    \n",
    "    for i in range(0,len(x)):\n",
    "        x[i] = x[i] > 0.5\n",
    "    cols = []\n",
    "    for j in range(0, n):\n",
    "        if x[j] == 1:\n",
    "            cols.append(j)\n",
    "    z1_prime = extract_subset(X_train, cols)\n",
    "    z2_prime = extract_subset(X_eval, cols)\n",
    "    clf = GNB()\n",
    "    clf.fit(z1_prime, Y_train)\n",
    "    y_pred = clf.predict(z2_prime)\n",
    "    \n",
    "    acc = sklearn.metrics.accuracy_score(Y_eval,y_pred)\n",
    "    pre = sklearn.metrics.precision_score(Y_eval,y_pred)\n",
    "    fscore = sklearn.metrics.f1_score(Y_eval,y_pred)\n",
    "    recall = sklearn.metrics.recall_score(Y_eval,y_pred)\n",
    "    return acc,pre,fscore,recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialise(m,n):\n",
    "    for i in range(0,m):\n",
    "        for j in range(0,n):\n",
    "            x = randint(0,1)\n",
    "            bat_pos[i].append(x)\n",
    "            bat_vel[i].append(0)\n",
    "\n",
    "        init_rate_vector.append(random.uniform(0, 1))\n",
    "\n",
    "        bat_frequency.append(init_rate_vector[i])\n",
    "        bat_loudness.append(random.uniform(1,2))\n",
    "        bat_rate.append(init_rate_vector[i])\n",
    "        bat_fitness.append(-infinity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def core():\n",
    "#     initialise(m,n)\n",
    "#     global_fit = -infinity\n",
    "#     for t in range (0,T):\n",
    "#         print(\"T:\" , t)\n",
    "#         for i in range(0,m):\n",
    "#             accuracy,pre,fscore,recall = svm_calc_fitness(bat_pos[i])\n",
    "#             '''\n",
    "#             with open(\"dumpPerformanceBat_svm_kpi.txt\", \"a\") as text_file:\n",
    "#                 text_file.write(\"{} {} {} {} {}\".format(accuracy,pre,fscore,recall,global_fit) + \"\\n\")\n",
    "#             with open(\"dumpPerformanceBat_svm.txt\", \"a\") as text_file:\n",
    "#                 text_file.write(\"{} {} {} {}\".format(t,accuracy,bat_pos[i].count(1),global_fit)+\"\\n\")\n",
    "#             #print(\"t={} accuracy={} #features={} global_fit={}\".format(t,accuracy,bat_pos[i].count(1),global_fit))\n",
    "#             '''\n",
    "#             acc = accuracy\n",
    "\n",
    "#             rand = randint(0,1)\n",
    "#             if rand < bat_loudness[i] and acc > bat_fitness[i]:\n",
    "#                 bat_fitness[i]=acc\n",
    "#                 bat_loudness[i]= alpha * bat_loudness[i]\n",
    "#                 bat_rate[i]= init_rate_vector[i] * (1 - math.exp(-(gamma * t)))\n",
    "\n",
    "#         maxindex,maxfit = max(enumerate(bat_fitness), key=operator.itemgetter(1))\n",
    "\n",
    "#         if maxfit>global_fit :\n",
    "#             global_fit = maxfit\n",
    "#             global_bat_pos = bat_pos[maxindex]\n",
    "\n",
    "#         for i in range(0,m): # for each bat\n",
    "#             beta = random.uniform(0,1)\n",
    "#             rand = random.uniform(0,1)\n",
    "#             AvgA = sum(bat_loudness)/len(bat_loudness)\n",
    "\n",
    "#             if rand > bat_rate[i] :\n",
    "#                 for j in range(0,n):\n",
    "#                     bat_pos[i][j] = bat_pos[i][j] + ( epsilon * AvgA )\n",
    "#                     sigma = randint(0,1)\n",
    "#                     if sigma < (1/(1+math.exp(-bat_pos[i][j]))) :\n",
    "#                         bat_pos[i][j]=1\n",
    "#                     else :\n",
    "#                         bat_pos[i][j]= 0\n",
    "\n",
    "#             rand = random.uniform(0,1)\n",
    "#             if rand < bat_loudness[i] and bat_fitness[i] < global_fit :\n",
    "#                 for j in range (0,n):\n",
    "#                     bat_frequency[i] = fmin + (fmax-fmin)* beta\n",
    "#                     bat_vel[i][j] = bat_vel[i][j] + (global_bat_pos[j]-bat_pos[i][j]) * bat_frequency[i]\n",
    "#                     bat_pos[i][j] = bat_pos[i][j] + bat_vel[i][j]\n",
    "#                     sigma = random.uniform(0,1)\n",
    "#                     if sigma < (1 / (1 + math.exp(-bat_pos[i][j]))) :\n",
    "#                         bat_pos[i][j]=1\n",
    "#                     else :\n",
    "#                         bat_pos[i][j]=0\n",
    "#         with open(\"dumpPerformanceBat_rf.txt\", \"a\") as text_file:\n",
    "#             text_file.write(\"{} {} {} \".format(t,global_bat_pos.count(1),global_fit)+\"\\n\")\n",
    "        \n",
    "\n",
    "\n",
    "#     feature_vector = global_bat_pos\n",
    "#     return feature_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def BAT_algo():\n",
    "#     feature_vector = core()\n",
    "#     return feature_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f = BAT_algo()\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneticAlgorithm():\n",
    "    \n",
    "    def __init__(self, X_train, X_dev, Y_train, Y_dev, number_bits_to_mutate = 25.0):\n",
    "        \n",
    "        \n",
    "        self.toolbox = base.Toolbox()\n",
    "        self.ind_mut_pb = float(number_bits_to_mutate / X_train.shape[1])\n",
    "        self.NGEN = 100\n",
    "        self.MUTPB = 0.2\n",
    "        self.CXPB = 0.5\n",
    "        self.POPULATION_SIZE = 70\n",
    "        self.NUMBER_TO_SELECT_FROM_POP = 35\n",
    "        self.init_pop = list()\n",
    "        self.X_train = X_train\n",
    "        self.X_dev = X_dev\n",
    "        self.Y_train = Y_train\n",
    "        self.Y_dev = Y_dev\n",
    "        \n",
    "    \n",
    "    def initialise_toolbox(self):\n",
    "        print('now initializing toolbox GA1')\n",
    "        # I want to maximize session overlap as well as length\n",
    "        creator.create(\"FitnessMax\", base.Fitness, weights=(1.0,))\n",
    "        # representing individual as a list\n",
    "        creator.create(\"Individual\", list, fitness=creator.FitnessMax)\n",
    "        # individual will be a list of 0/1\n",
    "        self.toolbox.register(\"attr_bool\", random.randint, 0, 1)\n",
    "        IND_DIMENSIONALITY = self.X_train.shape[1]\n",
    "        # create template for individual\n",
    "        self.toolbox.register(\"individual\", tools.initRepeat, creator.Individual, self.toolbox.attr_bool, n=IND_DIMENSIONALITY)\n",
    "        #self.toolbox.register(\"individual\", tools.initIterate, creator.Individual, self.get_ind)\n",
    "        # create template for population\n",
    "        self.toolbox.register(\"population\", tools.initRepeat, list, self.toolbox.individual)\n",
    "        print('toolbox initialised')\n",
    "    \n",
    "    \n",
    "    def initialise_fitness_function(self):\n",
    "        print('building and registering the fitness function')\n",
    "        \n",
    "        def fitness(individual):\n",
    "            \n",
    "            \n",
    "            accuracy,pre,fscore,recall = rf_calc_fitness(individual)\n",
    "            return fscore,\n",
    "            \n",
    "        \n",
    "        self.toolbox.register(\"evaluate\", lambda individual: fitness(individual))\n",
    "        self.toolbox.register(\"mate\", tools.cxOnePoint)\n",
    "        self.toolbox.register(\"mutate\", tools.mutFlipBit, indpb=self.MUTPB)\n",
    "        self.toolbox.register(\"select\", tools.selTournament, tournsize=3)\n",
    "        \n",
    "        print('fitness function ready')\n",
    "    \n",
    "    def run_algorithm(self):\n",
    "        \n",
    "        self.initialise_toolbox()\n",
    "        self.initialise_fitness_function()\n",
    "        \n",
    "        print('mutation probability was calculated at %f' % self.ind_mut_pb)\n",
    "        print('running the algorithm')\n",
    "        toolbox = self.toolbox\n",
    "        # create a population of size n\n",
    "        pop = toolbox.population(n=self.POPULATION_SIZE)\n",
    "        \n",
    "        \n",
    "        for gen in range(self.NGEN):\n",
    "            # Select the next generation individuals\n",
    "            if gen%5 == 0:\n",
    "                print(gen)\n",
    "            offspring = toolbox.select(pop, len(pop))\n",
    "            \n",
    "            for ind in offspring:\n",
    "                if ind.fitness.valid:\n",
    "                    pass\n",
    "            # Clone the selected individuals\n",
    "            offspring = list(map(toolbox.clone, offspring))\n",
    "\n",
    "            # Apply crossover on the offspring\n",
    "            for child1, child2 in zip(offspring[::2], offspring[1::2]):\n",
    "                if random.random() < self.CXPB:\n",
    "                    #toolbox.mate(child1, child2)\n",
    "                    tools.cxUniform(child1, child2, 0.5)\n",
    "                    del child1.fitness.values\n",
    "                    del child2.fitness.values\n",
    "\n",
    "            # Apply mutation on the offspring\n",
    "            for mutant in offspring:\n",
    "                if random.random() < self.MUTPB:\n",
    "                    # print('now doing mutation')\n",
    "                    toolbox.mutate(mutant)\n",
    "                    del mutant.fitness.values\n",
    "\n",
    "            # Evaluate the individuals with an invalid fitness\n",
    "            invalid_ind = [ind for ind in offspring if not ind.fitness.valid]\n",
    "            fitnesses = toolbox.map(toolbox.evaluate, invalid_ind)\n",
    "            \n",
    "            added = 0\n",
    "            for ind, fit in zip(invalid_ind, fitnesses):\n",
    "                ind.fitness.values = fit\n",
    "                \n",
    "\n",
    "            # The population is entirely replaced by the offspring\n",
    "            pop[:] = offspring\n",
    "            top = tools.selBest(pop, k=self.NUMBER_TO_SELECT_FROM_POP)\n",
    "            \n",
    "            # Dump best individual to file\n",
    "            fittest = tools.selBest(pop, k=1)[0]\n",
    "            count = 0\n",
    "            for i in range(0, len(fittest)):\n",
    "                if fittest[i] == 1:\n",
    "                    count = count + 1\n",
    "            with open(\"GA_performance.txt\", \"a\") as text_file:\n",
    "                accuracy,prec,fscore,recall = rf_calc_fitness(fittest)\n",
    "                text_file.write(\"{} {}\".format(count,fittest.fitness.values[0])+\"\\n\")\n",
    "                print(count,accuracy,prec,fscore,recall,fittest.fitness.values[0])\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        max_fitness = float(\"-inf\")\n",
    "        \n",
    "        for individual in tools.selBest(pop, k=1):\n",
    "            if individual.fitness.valid:\n",
    "                if individual.fitness.values[0] > max_fitness:\n",
    "                    max_fitness = individual.fitness.values[0]\n",
    "                    fittest_individual = individual\n",
    "                    \n",
    "        count = 0\n",
    "        for i in range(0, len(fittest_individual)):\n",
    "            if fittest_individual[i] == 1:\n",
    "                count = count + 1        \n",
    "        \n",
    "        print(count, max_fitness)\n",
    "        return fittest_individual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ga = GeneticAlgorithm(X_train, X_dev, Y_train, Y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now initializing toolbox GA1\n",
      "toolbox initialised\n",
      "building and registering the fitness function\n",
      "fitness function ready\n",
      "mutation probability was calculated at 0.002940\n",
      "running the algorithm\n",
      "0\n",
      "4240 0.8363636363636363 0.7524752475247525 0.484076433121019 0.3568075117370892 0.484076433121019\n",
      "4235 0.8313131313131313 0.6982758620689655 0.4924012158054711 0.38028169014084506 0.4924012158054711\n",
      "4207 0.8353535353535354 0.7083333333333334 0.5105105105105106 0.39906103286384975 0.5105105105105106\n",
      "4214 0.8343434343434344 0.696 0.5147928994082839 0.4084507042253521 0.5147928994082839\n",
      "4223 0.8383838383838383 0.7226890756302521 0.5180722891566265 0.40375586854460094 0.5180722891566265\n",
      "5\n",
      "4223 0.8383838383838383 0.7226890756302521 0.5180722891566265 0.40375586854460094 0.5180722891566265\n",
      "4243 0.8353535353535354 0.6984126984126984 0.5191740412979351 0.4131455399061033 0.5191740412979351\n",
      "4245 0.8404040404040404 0.7131782945736435 0.5380116959064328 0.431924882629108 0.5380116959064328\n",
      "4245 0.8404040404040404 0.7131782945736435 0.5380116959064328 0.431924882629108 0.5380116959064328\n",
      "4245 0.8404040404040404 0.7131782945736435 0.5380116959064328 0.431924882629108 0.5380116959064328\n",
      "10\n",
      "4219 0.8444444444444444 0.7251908396946565 0.5523255813953488 0.4460093896713615 0.5523255813953488\n",
      "4219 0.8444444444444444 0.7251908396946565 0.5523255813953488 0.4460093896713615 0.5523255813953488\n",
      "4213 0.8454545454545455 0.7380952380952381 0.5486725663716815 0.43661971830985913 0.5486725663716815\n",
      "4231 0.8454545454545455 0.7419354838709677 0.5459940652818991 0.431924882629108 0.5459940652818991\n",
      "4256 0.8505050505050505 0.773109243697479 0.5542168674698796 0.431924882629108 0.5542168674698796\n",
      "15\n",
      "4183 0.8474747474747475 0.7384615384615385 0.5597667638483965 0.4507042253521127 0.5597667638483965\n",
      "4202 0.8505050505050505 0.7559055118110236 0.5647058823529412 0.4507042253521127 0.5647058823529412\n",
      "4202 0.8505050505050505 0.7559055118110236 0.5647058823529412 0.4507042253521127 0.5647058823529412\n",
      "4184 0.8454545454545455 0.7238805970149254 0.5590778097982708 0.45539906103286387 0.5590778097982708\n",
      "4184 0.8454545454545455 0.7238805970149254 0.5590778097982708 0.45539906103286387 0.5590778097982708\n",
      "20\n",
      "4207 0.8494949494949495 0.7424242424242424 0.5681159420289855 0.460093896713615 0.5681159420289855\n",
      "4238 0.8525252525252526 0.7596899224806202 0.5730994152046783 0.460093896713615 0.5730994152046783\n",
      "4238 0.8525252525252526 0.7596899224806202 0.5730994152046783 0.460093896713615 0.5730994152046783\n",
      "4238 0.8525252525252526 0.7596899224806202 0.5730994152046783 0.460093896713615 0.5730994152046783\n",
      "4238 0.8525252525252526 0.7596899224806202 0.5730994152046783 0.460093896713615 0.5730994152046783\n",
      "25\n",
      "4219 0.8525252525252526 0.7557251908396947 0.5755813953488372 0.4647887323943662 0.5755813953488372\n",
      "4249 0.8565656565656565 0.784 0.5798816568047337 0.460093896713615 0.5798816568047337\n",
      "4262 0.8555555555555555 0.7734375 0.5806451612903226 0.4647887323943662 0.5806451612903226\n",
      "4262 0.8555555555555555 0.7734375 0.5806451612903226 0.4647887323943662 0.5806451612903226\n",
      "4262 0.8555555555555555 0.7734375 0.5806451612903226 0.4647887323943662 0.5806451612903226\n",
      "30\n",
      "4262 0.8555555555555555 0.7734375 0.5806451612903226 0.4647887323943662 0.5806451612903226\n",
      "4227 0.8545454545454545 0.7593984962406015 0.5838150289017341 0.47417840375586856 0.5838150289017341\n",
      "4257 0.8545454545454545 0.7633587786259542 0.5813953488372093 0.4694835680751174 0.5813953488372093\n",
      "4241 0.8545454545454545 0.7555555555555555 0.5862068965517241 0.4788732394366197 0.5862068965517241\n",
      "4251 0.8555555555555555 0.7692307692307693 0.5830903790087464 0.4694835680751174 0.5830903790087464\n",
      "35\n",
      "4251 0.8555555555555555 0.7692307692307693 0.5830903790087464 0.4694835680751174 0.5830903790087464\n",
      "4259 0.8565656565656565 0.7795275590551181 0.5823529411764705 0.4647887323943662 0.5823529411764705\n",
      "4240 0.8565656565656565 0.7751937984496124 0.5847953216374269 0.4694835680751174 0.5847953216374269\n",
      "4240 0.8565656565656565 0.7751937984496124 0.5847953216374269 0.4694835680751174 0.5847953216374269\n",
      "4256 0.8575757575757575 0.7769230769230769 0.5889212827988338 0.47417840375586856 0.5889212827988338\n",
      "40\n",
      "4256 0.8575757575757575 0.7769230769230769 0.5889212827988338 0.47417840375586856 0.5889212827988338\n",
      "4256 0.8575757575757575 0.7769230769230769 0.5889212827988338 0.47417840375586856 0.5889212827988338\n",
      "4267 0.8585858585858586 0.7874015748031497 0.5882352941176471 0.4694835680751174 0.5882352941176471\n",
      "4264 0.8575757575757575 0.7769230769230769 0.5889212827988338 0.47417840375586856 0.5889212827988338\n",
      "4267 0.8585858585858586 0.7874015748031497 0.5882352941176471 0.4694835680751174 0.5882352941176471\n",
      "45\n",
      "4267 0.8585858585858586 0.7874015748031497 0.5882352941176471 0.4694835680751174 0.5882352941176471\n",
      "4260 0.8595959595959596 0.7890625 0.592375366568915 0.47417840375586856 0.592375366568915\n",
      "4260 0.8595959595959596 0.7890625 0.592375366568915 0.47417840375586856 0.592375366568915\n",
      "4273 0.8606060606060606 0.7906976744186046 0.5964912280701755 0.4788732394366197 0.5964912280701755\n",
      "4260 0.8595959595959596 0.7890625 0.592375366568915 0.47417840375586856 0.592375366568915\n",
      "50\n",
      "4260 0.8595959595959596 0.7890625 0.592375366568915 0.47417840375586856 0.592375366568915\n",
      "4269 0.8585858585858586 0.7786259541984732 0.5930232558139534 0.4788732394366197 0.5930232558139534\n",
      "4269 0.8585858585858586 0.7786259541984732 0.5930232558139534 0.4788732394366197 0.5930232558139534\n",
      "4269 0.8585858585858586 0.7786259541984732 0.5930232558139534 0.4788732394366197 0.5930232558139534\n",
      "4256 0.8606060606060606 0.7952755905511811 0.5941176470588235 0.47417840375586856 0.5941176470588235\n",
      "55\n",
      "4256 0.8606060606060606 0.7952755905511811 0.5941176470588235 0.47417840375586856 0.5941176470588235\n",
      "4274 0.8575757575757575 0.7686567164179104 0.5936599423631124 0.4835680751173709 0.5936599423631124\n",
      "4274 0.8575757575757575 0.7686567164179104 0.5936599423631124 0.4835680751173709 0.5936599423631124\n",
      "4274 0.8575757575757575 0.7686567164179104 0.5936599423631124 0.4835680751173709 0.5936599423631124\n",
      "4265 0.8595959595959596 0.7846153846153846 0.5947521865889213 0.4788732394366197 0.5947521865889213\n",
      "60\n",
      "4265 0.8595959595959596 0.7846153846153846 0.5947521865889213 0.4788732394366197 0.5947521865889213\n",
      "4265 0.8595959595959596 0.7846153846153846 0.5947521865889213 0.4788732394366197 0.5947521865889213\n",
      "4265 0.8606060606060606 0.7906976744186046 0.5964912280701755 0.4788732394366197 0.5964912280701755\n",
      "4265 0.8606060606060606 0.7906976744186046 0.5964912280701755 0.4788732394366197 0.5964912280701755\n",
      "4265 0.8606060606060606 0.7906976744186046 0.5964912280701755 0.4788732394366197 0.5964912280701755\n",
      "65\n",
      "4265 0.8606060606060606 0.7906976744186046 0.5964912280701755 0.4788732394366197 0.5964912280701755\n",
      "4265 0.8606060606060606 0.7906976744186046 0.5964912280701755 0.4788732394366197 0.5964912280701755\n",
      "4265 0.8606060606060606 0.7906976744186046 0.5964912280701755 0.4788732394366197 0.5964912280701755\n",
      "4265 0.8606060606060606 0.7906976744186046 0.5964912280701755 0.4788732394366197 0.5964912280701755\n",
      "4265 0.8606060606060606 0.7906976744186046 0.5964912280701755 0.4788732394366197 0.5964912280701755\n",
      "70\n",
      "4265 0.8606060606060606 0.7906976744186046 0.5964912280701755 0.4788732394366197 0.5964912280701755\n",
      "4265 0.8606060606060606 0.7906976744186046 0.5964912280701755 0.4788732394366197 0.5964912280701755\n",
      "4265 0.8606060606060606 0.7906976744186046 0.5964912280701755 0.4788732394366197 0.5964912280701755\n",
      "4269 0.8585858585858586 0.7786259541984732 0.5930232558139534 0.4788732394366197 0.5930232558139534\n",
      "4269 0.8585858585858586 0.7786259541984732 0.5930232558139534 0.4788732394366197 0.5930232558139534\n",
      "75\n",
      "4269 0.8585858585858586 0.7786259541984732 0.5930232558139534 0.4788732394366197 0.5930232558139534\n",
      "4269 0.8585858585858586 0.7786259541984732 0.5930232558139534 0.4788732394366197 0.5930232558139534\n",
      "4269 0.8585858585858586 0.7786259541984732 0.5930232558139534 0.4788732394366197 0.5930232558139534\n",
      "4269 0.8585858585858586 0.7786259541984732 0.5930232558139534 0.4788732394366197 0.5930232558139534\n",
      "4269 0.8585858585858586 0.7786259541984732 0.5930232558139534 0.4788732394366197 0.5930232558139534\n",
      "80\n",
      "4269 0.8585858585858586 0.7786259541984732 0.5930232558139534 0.4788732394366197 0.5930232558139534\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4269 0.8585858585858586 0.7786259541984732 0.5930232558139534 0.4788732394366197 0.5930232558139534\n",
      "4269 0.8585858585858586 0.7786259541984732 0.5930232558139534 0.4788732394366197 0.5930232558139534\n",
      "4269 0.8585858585858586 0.7786259541984732 0.5930232558139534 0.4788732394366197 0.5930232558139534\n",
      "4269 0.8585858585858586 0.7786259541984732 0.5930232558139534 0.4788732394366197 0.5930232558139534\n",
      "85\n",
      "4269 0.8585858585858586 0.7786259541984732 0.5930232558139534 0.4788732394366197 0.5930232558139534\n",
      "4269 0.8585858585858586 0.7786259541984732 0.5930232558139534 0.4788732394366197 0.5930232558139534\n",
      "4269 0.8585858585858586 0.7786259541984732 0.5930232558139534 0.4788732394366197 0.5930232558139534\n",
      "4269 0.8585858585858586 0.7786259541984732 0.5930232558139534 0.4788732394366197 0.5930232558139534\n",
      "4269 0.8585858585858586 0.7786259541984732 0.5930232558139534 0.4788732394366197 0.5930232558139534\n",
      "90\n",
      "4269 0.8585858585858586 0.7786259541984732 0.5930232558139534 0.4788732394366197 0.5930232558139534\n",
      "4269 0.8585858585858586 0.7786259541984732 0.5930232558139534 0.4788732394366197 0.5930232558139534\n",
      "4269 0.8585858585858586 0.7786259541984732 0.5930232558139534 0.4788732394366197 0.5930232558139534\n",
      "4269 0.8585858585858586 0.7786259541984732 0.5930232558139534 0.4788732394366197 0.5930232558139534\n",
      "4269 0.8585858585858586 0.7786259541984732 0.5930232558139534 0.4788732394366197 0.5930232558139534\n",
      "95\n",
      "4269 0.8585858585858586 0.7786259541984732 0.5930232558139534 0.4788732394366197 0.5930232558139534\n",
      "4269 0.8585858585858586 0.7786259541984732 0.5930232558139534 0.4788732394366197 0.5930232558139534\n",
      "4269 0.8585858585858586 0.7786259541984732 0.5930232558139534 0.4788732394366197 0.5930232558139534\n",
      "4269 0.8585858585858586 0.7786259541984732 0.5930232558139534 0.4788732394366197 0.5930232558139534\n",
      "4269 0.8585858585858586 0.7786259541984732 0.5930232558139534 0.4788732394366197 0.5930232558139534\n",
      "4269 0.5930232558139534\n"
     ]
    }
   ],
   "source": [
    "fittest_individual = ga.run_algorithm()\n",
    "# takes ~30s per generation (for population of size 70)\n",
    "# total time ~1hr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'00010110000110100010000010000111001010000110110111011000110010111000110000100110111000000110101101111110100110101100001011100111100001010100000111101111100101101111110001000101000010110000100000010110000111000101100011110001111100011100101100111111011011100010100000101110100100100001101111111010101010111001101101000010110010001101011011000000000100111100111101010000111110100110011110100011000010110001001111110100000000011100001110100101110001101111011101001011101100010100101011110110011111000111100000110110001010000010111001011111011001110100110010100010111000111101011100100100000011111001111111011010101111000101010001001011101110011011011111100101101011000100100010001111011101111000000100000001111111011001100110010101110001101011101111010100111001110000001101100100101101000011010001001001111110000100000001111010001011000011001011100000010110000110110111101010000001010010011001100000000100011110011101010001100000110100100011011011100101101000010000110000001011000011010100111100010111001011010010001100110100011001111101011001110010011011101110011101110011011011111001001100101010100100001101010110110000001000111011100100011011110111001111010001001110100001100111111101110111000100111110001011110010110001010100001001011001010011000001100010100010011011010011100101001001001011001011001111111110000110101111101100101000010011100000111100111010011000010100000011011000001101000110111000001111110100100010000111101101101111110010010010010000000000001010010000001000111100110000010100101111011001111111110100101111111111010001110011110110001100111101010000011001101011111100110111110101101111000111011110100011010101111101100011100101000101010000111001011001010101100110011000000011000100000011101010001001010101001000111100101010001100011000000010111110010110010001111001010000010100111000110000110001010010101111100001011000100010111110010010111011000011010010101111000010100101110000110000110000010100011000100100011001011000001000011101111101101000011101010010010001101101011011111000110011001110100010110100001001010010011110010010001100000111111101010001110111111010011111001111100100101111110001100011000011000101111111000110101000101110011101110010110000000101000000101111110111110111001111110101000101011000110111001001001011101001001010011000000011011111101011000000001111101110001100101010110101000000100100100101001110000010101000011110111011110000101001111110011101101101101101111000100101001101010100101111001101100011010100110111010110000100001011100010111010000001101011101101100010111001001111011110011001101111011111000000111111000000000100000100101011011101101011011111000111000111001100000001001100100011011001000000000100111110010111001001000111001010110011110011100011110011101100100111000010000111010100111100010011000000001100110000001001111110111111001000111011100110000000100110101001010000000000111011101001100111000111001000101100101000011001101110110011010101111111000010011110011111010100000001110100100100100001000111010111010011011000010101101000100000100011010001010000001011111110011100111100011000111101000011000110001001010111101101101010100110111011010101010000001100001110010010011011000101010110001110100111111011100110111110110110000110001100010100001010000000111100011110100010001111110111001010010001110010101111011111101001011101101111001001001110001000001111001100001111111011011100010101100010001000011011000101101000111011101100000011101000111001111100010000110000011000111111101101101101011111100101010100011101101011001000101110010101000000101011011011001101110010110110111010000000111110100001110100100110011001110110101101000000100010001011110000001101001110100010011001001110101101110110001000011101010100110110111101001000000001001101011011011101011100100011001010011110101100110001001100110111000001101110000110010000111111101000010000011110100010010001110010011111011110000011001100111010110011110010001000011001001101000101100010000011111001111000101101101101010110001000111101010110000101110111101010000111000011011111101001000010100100000110010001101011100010001010110110001111100101110101100001111101001000001100001110001100101001011011010011011110010001111011100011111110000000100110111011101010101010010110101001101011001010101011101011001110101111100011101001001100110101101010110001111100100011101101111101111011010001101000100111101111110001001100100011011001000001111010111101000111101100111100011101001100111110010001101000110011001000000001010110001010001011110111011001001100111010010000011110010111001110100110110110001101110010010000111010110010101010101100101101111110011100101111000000010111000110100110001011001000001001111111000001001000110100101010000000010011100111110101110010001001011001001111011110101110010111000000111010111011111000111011010001111010101100011000111111111010101000011010100011010011010110110001011010001100001000001011001101000110101100001111001010000101011011001011110010100111110010111010101101110010010100001100011010010000111000001001000000011101010111111001010101101000001100000000100010111010110000100011100000011111111100101111000011101011100011011100001001110000111010101100000011011010100110110001110000001011000110011011111010100000100000111101110111101001100101011001100001000101110000110010111010111011110100011001011101111110100011100111100011110111100111101101101011101001101001111100111101010000101010111101001101010000111010000011100011100011010000111100000010001110110100111011000010001010110001010001001000011111011100101011101010110110000011000110111001000110010000111110100011010010110011010001111011101010000101010010010010001110011001010101110000010111101011000010100101011011111001100110011100111110101011000110011100111001111100100000101011100110110100001110111101110111101010100010101100101110010111011100110100111001110011001110011000111000000100101010101010111110111011001110111101110101111100100110101011001011101101100101101100000000110101110011010110001100000100001101101001010010111100001011101111000110100110000001001100010001110001101111100101101010000011100011000000010000010011110011111100111111000111111000010001101110001101111101011011100111110100110010010001000000001011010011111111110001111001011011010011000011111011111001001010001111110101100110100000100011001111011010010010001000111100100110000101100010100001011100110100011111111110011010010100110101101111000101011000111000001001011100110110101111100110000010101010110100010110110001011100011011101111000011111110111010011000010111110011101111001001100100110011001000001000000111011000000110101001011101110101001010011000100010011010010010000001010000011000000011101101011100011111011100110100001011110000101011111101100111010100010010100111001000100110111100100001011111100000010101000011110001000011010110010011100000111010111110000100110011010110110010000110100100010010011111010001011110110011001100101100110101100010100101101001101110101100000100001011001111000001000010001111101010010001001010101010101101010111111000010100111011101000000001100011011100100000000111100000111001010101010101011010001110110101101000101110101011111101011111111111010100001110010101110111010001000100011101010110000010100001001000001110110110011110111101111111000101111101011010000111111101110110010101111111100000010101110010101111000010111100110100011011000111110010010110011000001111100011110100010010001100101011000011100000101110100111100010101110100011000010111100110110010101110100011100110001110010110111110001101011010100011010110110010110100111010101100101001110111111011011111000110111010001011010101101001110101101111101001110000010100000111010001100100101111011101110111010100101100000011110111011111110110101010100110101100101111110100100010110100010000010110000010111101100100111111100000010010101111010001111100010010001001110010000110000000110111010100000001110010011010100001111001100010111011000011110111101100010101110010111110110000111010010100110010001110011010001001100100100011001111011111101111000010000111111100111000010111011110111010101010010000111000110110010101100110010101111001011011100110010100111001011101101001001100010101111111001000011111011011101100110101100010111011000101110010110011111011000000001100001100010100110101101100101010001000101110110111100100101110100100000111100010011110101010100010001100110000011111010011011001111011111101000000111000101111010001100110111000010110001101001111111010101011010001000000101100111111101100010110100101011110011101000010001011000100001000111001110001010010100101010100010011111001100101110101000000110111110000000011111111100111001'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fittest_individual # List[Boolean]\n",
    "''.join([str(int(x)) for x in fittest_individual])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8585858585858586,\n",
       " 0.7786259541984732,\n",
       " 0.5930232558139534,\n",
       " 0.4788732394366197)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# devset\n",
    "acc, pre, fscore, recall = rf_calc_fitness(fittest_individual)\n",
    "acc, pre, fscore, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.818342151675485, 0.6633663366336634, 0.464471403812825, 0.35733333333333334)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testset\n",
    "acc, pre, fscore, recall = rf_calc_fitness(fittest_individual, mode='test')\n",
    "acc, pre, fscore, recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code Flow\n",
    "- Feature extraction from the corpus (uni, bi, tri, tf-idf, lda, pos, nrc)\n",
    "- GA (meta-heuristic) for feature selection\n",
    "  - population of individuals, where each individual corresponds to a bitmask of features to select\n",
    "  - individuals evolve over the generations by cross-over and mutation\n",
    "  - fitness of individuals is evaluated using F1 score (this score is calculated on devset by fitting the model with a small amount of trainset for guiding GA)\n",
    "  - after GA finishes, we end up we the fittest individual ie the optimal feature set (denoted by a bitmask) (giving a good reduction of 50%)\n",
    "- Finally we train our model on the complete training set based on the selected features and evaluate it on testset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
